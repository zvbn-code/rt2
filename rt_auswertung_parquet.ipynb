{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertung der Parquet Dateien aus dem Echtzeitarchiv V14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import der Module und Setzen Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "import logging\n",
    "log_file = f\"log/log_rt.txt\"\n",
    "logging.basicConfig(filename=log_file, \n",
    "                        level=logging.DEBUG,\n",
    "                        style=\"{\",\n",
    "                        format=\"{asctime} [{levelname:8}] {message}\",\n",
    "                        datefmt=\"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Auswertung parquet gestartet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetzt = dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "gestern= (dt.date.today() - dt.timedelta(1)).strftime('%Y-%m-%d')\n",
    "letzte07tage= (dt.date.today() - dt.timedelta(7)).strftime('%Y-%m-%d')\n",
    "letzte14tage= (dt.date.today() - dt.timedelta(14)).strftime('%Y-%m-%d')\n",
    "letzte21tage= (dt.date.today() - dt.timedelta(21)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(jetzt, letzte21tage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau der class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rt_duck:    \n",
    "    #db_name=':memory:'\n",
    "    db_name = 'db/rt_archiv.db'\n",
    "    \n",
    "    def __init__(self, db_name=db_name):\n",
    "        # Initialize the DuckDB connection\n",
    "        self.conn = duckdb.connect(database=db_name)\n",
    "        self.cursor = self.conn.cursor()\n",
    "        self.cursor.sql(f\"\"\"INSTALL postgres;\n",
    "                            LOAD postgres;\n",
    "                            ATTACH 'dbname=zvbn_postgis user={config['POSTGRES_USER']} host=127.0.0.1 password={config['POSTGRES_PW']}' AS db_dm (TYPE POSTGRES, READ_ONLY);\"\"\"\n",
    "                        )\n",
    "        self.cursor.sql(\"create or replace table lin_buendel as select * from db_dm.basis.lin_buendel\")\n",
    "        sql_lin = \"\"\"\n",
    "        Create or replace table linien as \n",
    "        SELECT nummer AS linie, buendel, ebene, dlid, id \n",
    "        FROM db_dm.basis.linien \n",
    "        WHERE buendel IS NOT NULL AND aktiv IS TRUE \n",
    "        ORDER BY buendel, ebene, nummer \"\"\"\n",
    "        self.cursor.sql(sql_lin)\n",
    "\n",
    "    def create_table_fahrten(self, server):\n",
    "        \"\"\" erstellt eine Tabelle fshrten aus den Parquet Files Fahrten fahrten_yyyy_mm_dd.parquet\"\"\"\n",
    "        sql_create = f\"create or replace table fahrten as select * from read_parquet('out/parquet/{server}/fahrten*.parquet',  union_by_name = true, filename = true)\"\n",
    "        self.cursor.execute(sql_create)\n",
    "        #self.cursor(\"update fahrten \")\n",
    "        self.cursor.sql(\"alter table fahrten add column if not exists lineid_short VARCHAR\")\n",
    "        self.cursor.sql(\"\"\"update fahrten \n",
    "                set lineid_short = concat_ws(':', split_part(lineid,':', 1), split_part(lineid,':', 2), split_part(lineid,':', 3))\"\"\")\n",
    "        self.cursor.sql(\"\"\"select distinct lineid, \n",
    "                concat_ws(':', split_part(lineid,':', 1), split_part(lineid,':', 2), split_part(lineid,':', 3)) \n",
    "                from fahrten\"\"\")\n",
    "\n",
    "        print(\"Table 'fahrten' created.\")\n",
    "\n",
    "    def create_table_zusatz(self, server):\n",
    "        \"\"\" erstellt eine Tabelle zusatz aus den Parquet Files Fahrten zusatz_yyyy_mm_dd.parquet\"\"\"\n",
    "        sql_create = f\"create or replace table zusatz as select * from read_parquet('out/parquet/{server}/zusatz*.parquet',  union_by_name = true, filename = true)\"\n",
    "        self.cursor.execute(sql_create)\n",
    "        print(\"Table 'zusatz' created.\")\n",
    "\n",
    "    def create_table_verlauf(self, server):\n",
    "        \"\"\" erstellt eine Tabelle zusatz aus den Parquet Files Fahrten verlauf_yyyy_mm_dd.parquet\"\"\"\n",
    "        sql_create = f\"create or replace table verlauf as select * from read_parquet('out/parquet/{server}/verlauf*.parquet',  union_by_name = true, filename = true)\"\n",
    "        self.cursor.execute(sql_create)\n",
    "        print(\"Table 'verlauf' created.\")\n",
    "\n",
    "    def create_vw_buendel(self, buendel):\n",
    "        \"\"\" erstellt sicht auf ein Linienbündel mit dem Namen vw_buendel\"\"\"\n",
    "        sql_buendel = f\"\"\"create or replace view vw_buendel as\n",
    "                                (select f.datum, l.buendel, l.ebene, f.vu, f.fnr, f.lineshort,f.lineid_short, f.hasrealtime, \n",
    "                                f.journey_cancelled, f.reported_cancelled, f.ts_reported_cancelled\n",
    "        \n",
    "                                from fahrten f                                         \n",
    "                                left outer join linien l on f.lineid_short = l.dlid \n",
    "                                 where buendel like '%{buendel}%') \"\"\"\n",
    "        self.cursor.execute(sql_buendel)\n",
    "        \n",
    "\n",
    "    def anzahl_fahrten(self):        \n",
    "        return self.cursor.sql(\"from fahrten\").shape[0]\n",
    "    \n",
    "    def anzahl_fahrten_betreiber(self):\n",
    "        return self.cursor.sql(\"select vu, count(vu) as count from fahrten group by vu order by count desc\")\n",
    "    \n",
    "    def verbindung_schließen(self):\n",
    "        \"\"\" Schließen der DB Verbindung\"\"\"\n",
    "        self.conn.close()\n",
    "        print(\"Verbindung zur DB geschlossen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen der class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = rt_duck()\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schließen der Verbindung\n",
    "#rt.verbindung_schließen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.create_table_fahrten(server = 'prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.create_table_zusatz(server = 'prod')\n",
    "rt.create_table_verlauf(server = 'prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.cursor.sql(\"\"\"from linien limit 5\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zusatz = rt.cursor.sql(\"\"\"select datum::date as datum, lineshort, fnr,  vu \n",
    "              from zusatz \n",
    "              where \n",
    "              lineshort in ('630' , '670')\n",
    "              -- and vu like 'Reisedienst von Rahden%' \n",
    "            and datum::date >= (current_date - interval 30 day)\n",
    "              group by all order \n",
    "              by lineshort, fnr \"\"\").df()\n",
    "\n",
    "df_zusatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.cursor.sql(\"select min(datum )::date as min_date, max(datum)::date as amx_date, count(*) as anzahl from fahrten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.create_vw_buendel('OHZ Ost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.cursor.sql(\"from fahrten where datum = '2024-11-01' limit 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Häufung von Fahrten ohne Echtzeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fahrten_ohne_ez = rt.cursor.sql(\"\"\"\n",
    "              \n",
    "                select datum::date as datum, ebene, lineshort , fnr, hasrealtime\n",
    "               \n",
    "                from vw_buendel \n",
    "                where datum >= (current_date - interval 30 day) and hasrealtime = false\n",
    "                group by all\n",
    "                order by ebene, lineshort, fnr\n",
    "    \n",
    "              \"\"\").df()\n",
    "\n",
    "df_fahrten_ohne_ez_zusatz = df_fahrten_ohne_ez.merge(df_zusatz, left_on = ['datum', 'fnr'], right_on = ['datum', 'fnr'], how='left')\n",
    "df_fahrten_ohne_ez_zusatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fahrten_mit_nicht_vollstaendiger_echtzeit = rt.cursor.sql(\"\"\"\n",
    "              select * from \n",
    "                (select ebene, lineshort , fnr, count(*) as anz, count(*) filter (hasRealtime) as anz_rt, round(anz_rt/anz,2) as quote,\n",
    "                max(datum::date) filter (hasRealtime) as letzte_lieferung\n",
    "                from vw_buendel \n",
    "                where datum >= (current_date - interval 30 day)\n",
    "                group by all\n",
    "                order by ebene, lineshort, fnr)\n",
    "              where quote < 1\n",
    "              \"\"\").df()\n",
    "\n",
    "df_fahrten_mit_nicht_vollstaendiger_echtzeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = 'out/nicht_vollstaendig.xlsx'\n",
    "sn01 = '01 fahrten_rt_kl_100_roz'\n",
    "sn02 = '02 zusatzfahrten'\n",
    "sn03 = '03 ohne ez merge zusatz'\n",
    "\n",
    "with pd.ExcelWriter(xl, engine='openpyxl') as writer: \n",
    "    df_fahrten_mit_nicht_vollstaendiger_echtzeit.to_excel(writer, index=False, sheet_name=sn01)\n",
    "    writer.book[sn01].freeze_panes = 'A2'\n",
    "    writer.book[sn01].auto_filter.ref='A:H'\n",
    "\n",
    "    df_zusatz.to_excel(writer, index=False, sheet_name=sn02)\n",
    "    writer.book[sn02].freeze_panes = 'A2'\n",
    "    writer.book[sn02].auto_filter.ref='A:H'\n",
    "\n",
    "    df_fahrten_ohne_ez_zusatz.to_excel(writer, index=False, sheet_name=sn03)\n",
    "    writer.book[sn03].freeze_panes = 'A2'\n",
    "    writer.book[sn03].auto_filter.ref='A:H'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = rt.cursor.sql(\"\"\"\n",
    "                   (select \n",
    "                    datum::date as datum, ebene, lineshort, lineid_short, count(*) anz,\n",
    "                    count(*) filter (hasRealtime) anz_rt, round(anz_rt/ anz,2) anteil_rt, \n",
    "                    max(datum) filter (hasRealtime) letzte_lieferung\n",
    "                    from vw_buendel \n",
    "                    where datum >= date_trunc('month', (date_trunc('month',current_date) - interval 1 day)::date)\n",
    "                    and datum <= (date_trunc('month',current_date) - interval 1 day)::date\n",
    "                  \n",
    "                    group by all\n",
    "\n",
    "                    order by datum::date)\n",
    "                  \"\"\")\n",
    "#q.filter(\"lineshort in ('S35', '350')\") #mit filter einfache Abfragen\n",
    "\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abfrage für den letzten Monat\n",
    "q_pivot_lm = rt.cursor.sql(\"\"\"\n",
    "                    pivot (select \n",
    "                            datum::date as datum, ebene, lineshort, lineid_short, count(*) anz,\n",
    "                            count(*) filter (hasRealtime) anz_rt, round(anz_rt/ anz,2) anteil_rt\n",
    "                        from vw_buendel \n",
    "                        where datum >= date_trunc('month', (date_trunc('month',current_date) - interval 1 day)::date)\n",
    "                            and datum <= (date_trunc('month',current_date) - interval 1 day)::date\n",
    "                        group by all\n",
    "                        )\n",
    "                    on datum\n",
    "                    using sum(anteil_rt)\n",
    "                    group by lineshort, ebene\n",
    "                    order by ebene, lineshort\"\"\")\n",
    "\n",
    "q_pivot_lm.df().fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abfrage für die letzten 30 Tage\n",
    "q_pivot_lm = rt.cursor.sql(\"\"\"\n",
    "                    pivot (select \n",
    "                            datum::date as datum, ebene, lineshort, lineid_short, count(*) anz,\n",
    "                            count(*) filter (hasRealtime) anz_rt, round(anz_rt/ anz,2) anteil_rt\n",
    "                        from vw_buendel \n",
    "                        where datum >= (current_date - interval 30 day)\n",
    "                        group by all\n",
    "                        )\n",
    "                    on datum\n",
    "                    using sum(anteil_rt)\n",
    "                    group by lineshort, ebene\n",
    "                    order by ebene, lineshort\"\"\")\n",
    "\n",
    "q_pivot_lm.df().style.background_gradient(cmap=\"RdYlGn\", axis = None,  vmin=0.5, vmax=1).highlight_null(color='white').format(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.anzahl_fahrten_betreiber().df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Anzahl Fahrten gesamt {rt.anzahl_fahrten()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ohne class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(f\"\"\"INSTALL postgres;\n",
    "LOAD postgres;\n",
    "ATTACH 'dbname=zvbn_postgis user={config['POSTGRES_USER']} host=127.0.0.1 password={config['POSTGRES_PW']}' AS db_dm (TYPE POSTGRES, READ_ONLY);\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"create or replace table lin_buendel as select * from db_dm.basis.lin_buendel\")\n",
    "con.sql(\"select * from lin_buendel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_lin = \"\"\"\n",
    "        Create or replace table linien as \n",
    "        SELECT nummer AS linie, buendel, ebene, dlid, id \n",
    "        FROM db_dm.basis.linien \n",
    "        WHERE buendel IS NOT NULL AND aktiv IS TRUE \n",
    "        ORDER BY buendel, ebene, nummer \"\"\"\n",
    "con.sql(sql_lin)\n",
    "con.sql(\"select * from linien\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abruf der Parquet Files (Tagespakete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'prod'\n",
    "con.sql(f\"create or replace table fahrten as select * from read_parquet('out/parquet/{server}/fahrten*.parquet',  union_by_name = true, filename = true)\")\n",
    "con.sql(f\"create or replace table verlauf as select * from read_parquet('out/parquet/{server}/verlauf*.parquet',  union_by_name = true, filename = true)\")\n",
    "con.sql(f\"create or replace table zusatz as select * from read_parquet('out/parquet/{server}/zusatz*.parquet',  union_by_name = true, filename = true)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ermitteln und Löschen von nicht gewollten Betreibern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con.sql(\"select distinct vu from fahrten where vu like '%Weser%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"describe fahrten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"select count(*), datum from fahrten group by datum order by datum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #True / False um ggf. weiterhin alles durchlaufen zu lassen\n",
    "    print('Löschen von Betreibern')\n",
    "    con.sql(\"delete from fahrten where vu not in ('Weser-Ems-Bus Betrieb Bremen', 'Weser-Ems-Bus Auftragnehmerleistungen')\")\n",
    "    #con.sql(\"delete from verlauf where vu not in ('Weser-Ems-Bus Betrieb Bremen', 'Weser-Ems-Bus Auftragnehmerleistungen')\")\n",
    "    #con.sql(\"delete from zusatz where vu not in ('Weser-Ems-Bus Betrieb Bremen', 'Weser-Ems-Bus Auftragnehmerleistungen')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(f\"select count(*) from fahrten where datum >= (current_date - interval 100 days)\").df().values.tolist()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anzahl_fahrten = con.sql(f\"select count(*) from fahrten where datum >= '{letzte14tage}'\").df().values.tolist()[0][0]\n",
    "print(f\"\"\"Anzahl Fahrten: {anzahl_fahrten},  Länge Verlauf: {con.sql(\"select count(*) from verlauf\").df().values.tolist()[0][0]}    \"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"select \n",
    "            datum, \n",
    "            fahrtstartstationname, \n",
    "           strftime( cast(fahrtstarttime as TIMESTAMPTZ), '%H:%M') as fahrtstart,\n",
    "           fahrtendstationname,\n",
    "           strftime( cast(fahrtendtime as TIMESTAMPTZ), '%H:%M') as fahrtende,\n",
    "            \n",
    "            deviceid, \n",
    "            split_part(deviceid, '-', 2) as fnr, \n",
    "            cast(((cast(split_part(split_part(deviceid, '-', 3), '#', 1) as int64) - 8000000000000) / 1000) as int64) as m2, \n",
    "        from fahrten \n",
    "        where deviceid like '%680%DBRB%' and datum = '2024-10-29'\n",
    "        order by datum, fahrtstarttime\n",
    "        \n",
    "        \"\"\").df()\n",
    "#.to_excel('out/web.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anzahl der Fahrten je Betreiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"select journeyOperator, count(journeyOperator) as count from verlauf group by journeyOperator order by count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fahrten mit hohen Verspätungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"select distinct deviceid from verlauf where dep_del > 100\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"describe fahrten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verkürzung der DLID\n",
    "- Zum Teil weren bei mehreren Betreibern einer Linie TLID mit vierteiliger DLID geliefert \n",
    "- Verkürzung ermöglicht die Verknüpfung mit Liste aus DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"alter table fahrten add column if not exists lineid_short VARCHAR\")\n",
    "con.sql(\"\"\"update fahrten \n",
    "        set lineid_short = concat_ws(':', split_part(lineid,':', 1), split_part(lineid,':', 2), split_part(lineid,':', 3))\"\"\")\n",
    "con.sql(\"\"\"select distinct lineid, \n",
    "        concat_ws(':', split_part(lineid,':', 1), split_part(lineid,':', 2), split_part(lineid,':', 3)) \n",
    "        from fahrten\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Über HIM gemeldete Ausfälle (ts_reported_cancelled gefüllt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fahrten_ausfall_him = con.sql(f\"\"\"\n",
    "                              select vu, fnr, ts_reported_cancelled, journey_cancelled \n",
    "                              from fahrten f \n",
    "                              where ts_reported_cancelled != '' and f.datum >= '{letzte14tage}'\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Echzeitquote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nach Linie und Betreiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ez_quote_betreiber = con.sql(f\"\"\"\n",
    "        select l.buendel, l.ebene,f.datum, f.vu, f.lineshort,f.lineid_short, count(f.hasRealtime) filter (f.hasRealtime = True) ez_true, count(f.*) count, \n",
    "        round(ez_true / count * 100, 1) anteil_ez\n",
    "        from fahrten f\n",
    "        left outer join linien l on f.lineid_short = l.dlid\n",
    "        where f.datum >= '{letzte14tage}'              \n",
    "        group by f.lineid_short, f.vu, f.datum, f.lineshort, f.lineid_short, l.buendel, l.ebene\n",
    "        order by f.vu, f.lineid_short\n",
    "        \"\"\").df()\n",
    "df_ez_quote_betreiber['buendel'] = df_ez_quote_betreiber['buendel'].fillna('-')\n",
    "df_ez_quote_betreiber['ebene'] = df_ez_quote_betreiber['ebene'].fillna('-')\n",
    "anteil_ez_pivot_betreiber = pd.pivot_table(df_ez_quote_betreiber, index=['buendel','ebene', 'vu', 'lineshort'], columns='datum', values='anteil_ez').reset_index()\n",
    "anteil_ez_pivot_betreiber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nach Linie (ohne Betreiber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ez_quote_o_betreiber = con.sql(f\"\"\"\n",
    "        select l.buendel, l.ebene,f.datum, f.lineshort,f.lineid_short, count(f.hasRealtime) filter (f.hasRealtime = True) ez_true, count(f.*) count, \n",
    "        round(ez_true / count * 100, 1) anteil_ez\n",
    "        from fahrten f        \n",
    "        left outer join linien l on f.lineid_short = l.dlid      \n",
    "        where f.datum >= '{letzte14tage}'        \n",
    "        group by f.lineid_short, f.datum, f.lineshort, f.lineid_short, l.buendel, l.ebene\n",
    "        order by f.lineid_short\n",
    "        \"\"\").df()\n",
    "df_ez_quote_o_betreiber['buendel'] = df_ez_quote_o_betreiber['buendel'].fillna('-')\n",
    "df_ez_quote_o_betreiber['ebene'] = df_ez_quote_o_betreiber['ebene'].fillna('-')\n",
    "anteil_ez_pivot_o_betreiber = pd.pivot_table(df_ez_quote_o_betreiber, index=['buendel','ebene', 'lineshort'], columns='datum', values='anteil_ez').reset_index()\n",
    "anteil_ez_pivot_o_betreiber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fahrten ohne Echtzeit Ebene 1/1+ und 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fahrten_ohne_ez_ebenen_1_1p_2 = con.sql(f\"\"\"\n",
    "        select f.datum, l.buendel, l.ebene, f.vu, f.fnr, f.lineshort,f.lineid_short, f.hasrealtime, f.journey_cancelled, f.reported_cancelled, f.ts_reported_cancelled\n",
    "        \n",
    "        from fahrten f\n",
    "                                           \n",
    "        left outer join linien l on f.lineid_short = l.dlid              \n",
    "        where l.ebene in ('1', '1+') and f.hasrealtime = False and f.datum >= '{letzte14tage}'\n",
    "                                           \n",
    "        order by f.datum, f.lineid_short\n",
    "        \"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fahrten_ausfall_1_1p_2 = con.sql(f\"\"\"\n",
    "        select f.datum, l.buendel, l.ebene, f.vu, f.fnr, f.lineshort,f.lineid_short, f.hasrealtime, f.journey_cancelled, f.reported_cancelled, f.ts_reported_cancelled\n",
    "        \n",
    "        from fahrten f\n",
    "                                    \n",
    "        left outer join linien l on f.lineid_short = l.dlid              \n",
    "        where l.ebene in ('1', '1+', '2') and (journey_cancelled = True or f.reported_cancelled = True) and \n",
    "        f.datum >= '{letzte14tage}'                            \n",
    "        order by f.datum, f.lineid_short\n",
    "        \"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ausgabe xlsx EZ Statistiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx = \"/var/www/rt_archiv/anteil_echtzeit_linien_vbn.xlsx\"\n",
    "sn00 = '00 Hilfe'\n",
    "sn01 = '01 pivot alle Linien betreiber'\n",
    "sn02 = '02 pivot alle Linien'\n",
    "sn03 = '03 fahrten ohne EZ 1 1+ 2'\n",
    "sn04 = '04 fahrten ohne EZ 1 1+ 3 grup'\n",
    "sn06 = '05 fahrten ausfall'\n",
    "sn07 = '06 fahrten ausfall über HIM'\n",
    "with pd.ExcelWriter(xlsx, engine=\"openpyxl\") as writer:\n",
    "    #Hilfeblatt\n",
    "    writer.book.create_sheet(sn00)\n",
    "    sheet = writer.book[sn00]\n",
    "    sheet['A1'] = f\"Erstellt: {dt.datetime.now().strftime('%Y-%m-%d %H:%M')} Zeitraum: {letzte14tage} bis {gestern}\"\n",
    "\n",
    "    sheet['A3'] = \"Inhalt\"\n",
    "    sheet['B4'] = f\"Blatt {sn01}: Pivot Echtzeitquote inkl. Betreiberkennung\"\n",
    "    sheet['B5'] = f\"Blatt {sn02}: Pivot Echtzeitquote ohne Betreiberkennung\"\n",
    "    sheet['B6'] = f\"Blatt {sn03}: Fahrten ohne Echtzeit\"\n",
    "    sheet['B7'] = f\"Blatt {sn04}: Fahrten ohne Echtzeit mit Anzahl\"\n",
    "    sheet['B8'] = f\"Blatt {sn06}: Fahrten Ausfall\"\n",
    "    sheet['B9'] = f\"Blatt {sn07}: Fahrten Ausfall über HIM\"\n",
    "\n",
    "    #mit Kennung der Betreiber\n",
    "    anteil_ez_pivot_betreiber.to_excel(writer, sheet_name=sn01, index=False)\n",
    "    writer.book[sn01].freeze_panes = 'e2'\n",
    "    writer.book[sn01].auto_filter.ref='A:H'\n",
    "    for cell in writer.book[sn01][\"1:1\"]:\n",
    "        cell.number_format = 'YYYY-MM-DD'\n",
    "    writer.book[sn01].column_dimensions['c'].width = 22\n",
    "    for c in ['D', 'E', 'F', 'G', 'H']:\n",
    "        writer.book[sn01].column_dimensions[c].width = 22        \n",
    "    for c in writer.book[sn01].iter_cols(min_col=4, max_col=anteil_ez_pivot_betreiber.shape[1]+4):\n",
    "                #ermitteln der Spalte column letter\n",
    "                cl = c[int(f\"{anteil_ez_pivot_betreiber.shape[0]}\")].column_letter\n",
    "                writer.book[sn01].column_dimensions[cl].width = 16\n",
    "\n",
    "    #Anteil EZ ohne Kennung der Betreiber\n",
    "    anteil_ez_pivot_o_betreiber.to_excel(writer, sheet_name=sn02, index=False)\n",
    "    writer.book[sn02].freeze_panes = 'd2'\n",
    "    writer.book[sn02].auto_filter.ref='A:H'\n",
    "    for cell in writer.book[sn02][\"1:1\"]:\n",
    "        cell.number_format = 'YYYY-MM-DD'\n",
    "    writer.book[sn02].column_dimensions['c'].width = 22\n",
    "    for c in ['D', 'E', 'F', 'G', 'H']:\n",
    "        writer.book[sn02].column_dimensions[c].width = 22 \n",
    "         \n",
    "    for c in writer.book[sn02].iter_cols(min_col=4, max_col=anteil_ez_pivot_o_betreiber.shape[1]+4):\n",
    "                #ermitteln der Spalte column letter\n",
    "                cl = c[int(f\"{anteil_ez_pivot_o_betreiber.shape[0]}\")].column_letter\n",
    "                writer.book[sn02].column_dimensions[cl].width = 16\n",
    "\n",
    "    ## Ausgabe der Fahrten ohne Echtzeit Ebene 1 und 1+ und 2 einzeln\n",
    "    df_fahrten_ohne_ez_ebenen_1_1p_2.to_excel(writer, sheet_name=sn03, index=False)\n",
    "    writer.book[sn03].freeze_panes = 'a2'\n",
    "    writer.book[sn03].auto_filter.ref='A:M'\n",
    "    for cell in writer.book[sn03][\"A\"]:\n",
    "        cell.number_format = 'YYYY-MM-DD'\n",
    "    writer.book[sn03].column_dimensions['A'].width = 18\n",
    "\n",
    "    ## Ausgabe der Fahrten ohne Echtzeit Ebene 1 und 1+ und 2 gruppiert mit Anzahl\n",
    "    df_fahrten_ohne_ez_ebenen_1_1p_2[['vu', 'fnr']].value_counts().reset_index().sort_values(['count', 'vu'], ascending=False).to_excel(writer, sheet_name=sn04, index=False)\n",
    "    writer.book[sn04].freeze_panes = 'a2'\n",
    "    writer.book[sn04].auto_filter.ref='A:H'\n",
    "    writer.book[sn04].column_dimensions['A'].width = 22   \n",
    "\n",
    "    ## Ausgabe der Fahrten Ausfall Ebene 1, 1+ und 2\n",
    "    df_fahrten_ausfall_1_1p_2.to_excel(writer, sheet_name=sn06, index=False)\n",
    "    writer.book[sn06].freeze_panes = 'a2'\n",
    "    writer.book[sn06].auto_filter.ref='A:M'\n",
    "    for cell in writer.book[sn06][\"A\"]:\n",
    "        cell.number_format = 'YYYY-MM-DD'\n",
    "    writer.book[sn06].column_dimensions['A'].width = 18\n",
    "\n",
    "    ## Ausgabe der Fahrten Ausfall über HIM\n",
    "    df_fahrten_ausfall_him.to_excel(writer, sheet_name=sn07, index=False)\n",
    "    writer.book[sn07].freeze_panes = 'a2'\n",
    "    writer.book[sn07].auto_filter.ref='A:M'\n",
    "    for cell in writer.book[sn07][\"A\"]:\n",
    "        cell.number_format = 'YYYY-MM-DD'\n",
    "    writer.book[sn07].column_dimensions['A'].width = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat_rt_canc = con.sql(\"\"\"\n",
    "        select \n",
    "            vu, \n",
    "            count(*) as anzahl, \n",
    "            count(*) filter (hasRealtime) as hasRealtime, \n",
    "            count(*) filter (realtimeHasEverBeenReported) as realtimeHasEverBeenReported,\n",
    "            count(*) filter (realtimehaseverbeenreported or hasrealtime) as rt_combined,\n",
    "            count(*) filter (journey_cancelled) as journey_cancelled,\n",
    "            count(*) filter (reported_cancelled) as reported_cancelled\n",
    "        from fahrten\n",
    "        where datum >= (current_date - interval 3 days)\n",
    "        group by all\n",
    "        order by vu\"\"\").df()\n",
    "df_stat_rt_canc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'reports/df_stat_rt_canc.xlsx'\n",
    "sheet_name = 'Stat RT Canc'\n",
    "df_stat_rt_canc = df_stat_rt_canc.sort_values(by='vu')\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    df_stat_rt_canc.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "    worksheet = writer.book[sheet_name]\n",
    "    worksheet.auto_filter.ref = worksheet.dimensions\n",
    "    worksheet.column_dimensions['A'].width = 30  # Set the width of column A to 30\n",
    "    worksheet.freeze_panes = 'A2'  # Freeze the first row\n",
    "    len = df_stat_rt_canc.shape[0]  # Get the number of rows\n",
    "    worksheet[f'B{len+3}'] = f'=subtotal(9,B2:B{len + 1})'  # Add a sum formula for column B\n",
    "    worksheet[f'C{len+3}'] = f'=subtotal(9,C2:C{len + 1})'  # Add a sum formula for column C\n",
    "    worksheet[f'D{len+3}'] = f'=subtotal(9,D2:D{len + 1})'  # Add a sum formula for column D\n",
    "    worksheet[f'E{len+3}'] = f'=subtotal(9,E2:E{len + 1})'  # Add a sum formula for column E\n",
    "    worksheet[f'F{len+3}'] = f'=subtotal(9,F2:F{len + 1})'  # Add a sum formula for column F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
