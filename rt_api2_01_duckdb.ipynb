{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfrage Schnittstelle und Ablage in DuckDBzum Hafas Echtzeit-Archiv Produktiv / Demo-System / Ablage in DuckDB\n",
    "\n",
    "Stand: 18.11.2023\n",
    "\n",
    "#### Aufgaben\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import datetime as dt\n",
    "import time\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "\n",
    "import tarfile\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import duckdb\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "from sqlalchemy import create_engine #als Alternative zu Mysql pyscopg2 Connector\n",
    "from sqlalchemy import text\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import para\n",
    "import rt_archiv_func_06 as rt_func #Import der benutzerdefinierten Funktionen\n",
    "reload(rt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermitteln verschiedener Zeitpunkte "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ermitteln der Zeitstempel\n",
    "jetzt = dt.datetime.now().strftime('%Y%m%d%H%M')\n",
    "heute = dt.date.today().strftime('%Y%m%d')\n",
    "heute_ll = dt.datetime.now().strftime('%d.%m.%Y %H:%M')\n",
    "gestern = (dt.date.today() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "vorgestern = (dt.datetime.now() - timedelta(2)).strftime('%Y-%m-%d')\n",
    "vorvierwochen = (dt.date.today() - timedelta(28)).strftime('%Y-%m-%d')\n",
    "vorsechswochen = (dt.date.today() - timedelta(42)).strftime('%Y-%m-%d')\n",
    "letztesiebentage = (dt.date.today() - timedelta(7)).strftime('%Y-%m-%d')\n",
    "\n",
    "print(f'Heute: {heute} \\nJetzt: {jetzt} \\nGestern: {gestern} \\nVorgestern: {vorgestern} \\nVor vier Wochen: {vorvierwochen} \\nVor sechs Wochen: {vorsechswochen}')\n",
    "print('vor einer Woche ' + letztesiebentage)\n",
    "#ermitteln des letzten Monats\n",
    "\n",
    "today = dt.date.today()\n",
    "first = today.replace(day=1) #auf den ersten des aktuellen Monats setzen\n",
    "lastmonth_last = first - dt.timedelta(days=1) # 1 Tag abziehen vom ersten Tag \n",
    "lastmonth_first = lastmonth_last.replace(day=1) #ersetzen des ersten Tages\n",
    "lastmonth_first_str = str(lastmonth_first)\n",
    "lastmonth_last_str = str(lastmonth_last)\n",
    "print(f'Erster Tag des letzen Monats: {lastmonth_first} und letzter Tag:  {lastmonth_last}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aktuelle Version der Schnittstellenbeschreibung unter \n",
    "- docs/SmartVMS Export API v12.pdf\n",
    "- docs/SmartVMS Export API v14_datatypes-1.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = '14' #14 auf demo und ab August 2023 auf prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zugriff auf Hafas RT Archiv Produktiv System und Zugriffsschlüssel\n",
    "myUrl = 'https://fahrplaner.vbn.de/archive/services/archiveExportService/v'+api_version+'?wsdl'\n",
    "clientID = 'PMQmY5p9y8kmoTno'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen der Linienliste / Zuordnung Bündel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen aus der lokalen DM Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zugriff auf die lokale Datenbank auf dem Wortmann Debian Server\n",
    "\n",
    "try:\n",
    "    engine = create_engine(\"postgresql+psycopg2://postgres:\"+para.key_dm_db+\"@127.0.0.1:5432/zvbn_postgis\")\n",
    "    #conn_dm = psycopg2.connect(database='zvbn_postgis', user='postgres', password=para.key_dm_db, host = '127.0.0.1')\n",
    "    sql_lin = 'SELECT nummer AS linie, buendel, \\'\\' AS rt_operator, ebene, dlid, id \\\n",
    "        FROM basis.linien \\\n",
    "        WHERE buendel IS NOT NULL AND aktiv IS TRUE \\\n",
    "        ORDER BY buendel, ebene, nummer'\n",
    "    sql_buendel = 'SELECT * FROM basis.lin_buendel'\n",
    "    df_lin_dm =  pd.read_sql(text(sql_lin), engine.connect())\n",
    "    df_buendel = pd.read_sql(text(sql_buendel), engine.connect())\n",
    "    df_lin_dm.to_csv('input/linien_dm.csv', sep=';', index=False)\n",
    "    print('Verbindung erfolgreich -lokale Datei aktualisiert')\n",
    "except:\n",
    "    df_lin_dm = pd.read_csv('input/linien_dm.csv', sep=';') #aktuelle Zuordnung Linie zu Bündel aus DM\n",
    "    print(f'Verbindung nicht erfolgreich - Verwendung lokale Datei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#External Linids, die nicht mit de:VBN starten\n",
    "df_lin_dm.fillna('-').query('not (dlid.str.startswith(\"de:VBN\") or dlid.str.startswith(\"-\"))').dlid.sort_values()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen der Filterparameter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papermill Parameter\n",
    "\n",
    "- Zelle ist mit Tags 'Parameters' versehen \n",
    "Parameter - nicht ändern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#auswahl =  ['DEL','OHZ West', 'OHZ Ost', 'OHZ Mitte', 'VER Nord'] #kann bei python Skript auch über Parameter Command Promppt gesteuert werden int(sys.argv[1]) oder Papermill\n",
    "auswahl = ['AM West']\n",
    "startDate = '2023-11-09'\n",
    "#endDate   = gestern\n",
    "#startDate = letztesiebentage #Beginn des Auswertungszeitraums\n",
    "endDate   = '2023-11-10'\n",
    "startendDate = '2023-11-17'\n",
    "#endDate  = gestern #Ende der Auswertung\n",
    "art = \"regional\" #Einstellen stadt oder regional für die Erstellung\n",
    "suffix = \"\" #besondere Endung z.B. für den Monatsbericht\n",
    "output_xml = False #Ob xml als Text ausgegeben werden soll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abfagen aller Daten für einen Tag über die Externallinid (de:VBN:* und Metronomlinien mit de:hvv:) de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:\n",
    "#lineExternalNamePattern Abfrage über DLID\n",
    "xml_request_dlid = ('<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" '\n",
    "               'xmlns:v'+api_version+'=\"http://v'+api_version+'.export.service.data.archive.itcs.hafas.hacon.de/\">'\n",
    "               '<soapenv:Header/><soapenv:Body><v'+api_version+':createArchiveJob>'\n",
    "               '<filter>'\n",
    "                    '<clientId>' + clientID + '</clientId>'                    \n",
    "                    '<startDate>' + startendDate + '</startDate>'\n",
    "                    '<endDate>' + startendDate + '</endDate>'\n",
    "                    '<lineExternalNamePattern>de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:</lineExternalNamePattern>'                \n",
    "                    '<hasRealtime>ALL</hasRealtime>'\n",
    "               '</filter>'\n",
    "               '</v' + api_version + ':createArchiveJob></soapenv:Body></soapenv:Envelope>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abfagen aller Daten für einen Tag über die Externallinid (de:VBN:* und Metronomlinien mit de:hvv:) de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:\n",
    "#lineExternalNamePattern Abfrage über DLID\n",
    "xml_request_spezial = ('<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" '\n",
    "               'xmlns:v'+api_version+'=\"http://v'+api_version+'.export.service.data.archive.itcs.hafas.hacon.de/\">'\n",
    "               '<soapenv:Header/><soapenv:Body><v'+api_version+':createArchiveJob>'\n",
    "               '<filter>'\n",
    "                    '<clientId>' + clientID + '</clientId>'                    \n",
    "                    '<startDate>' + startDate + '</startDate>'\n",
    "                    '<endDate>' + endDate + '</endDate>'\n",
    "                    '<lineExternalNamePattern>de:VBN:680*</lineExternalNamePattern>'                \n",
    "                    '<hasRealtime>ALL</hasRealtime>'\n",
    "               '</filter>'\n",
    "               '</v' + api_version + ':createArchiveJob></soapenv:Body></soapenv:Envelope>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testen des XML mit schöner Ausgabe\n",
    "dom = xml.dom.minidom.parseString(xml_request_dlid)\n",
    "pretty_xml_as_string = dom.toprettyxml()\n",
    "print(pretty_xml_as_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abfrage stellen und ermitteln der Export ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_ini = requests.post(myUrl, data=xml_request_dlid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.fromstring(req_ini.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_ini.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermitteln der ExportID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for child in root.iter('exportId'):\n",
    "    print(child.tag, child.attrib, child.text)\n",
    "    exportId = child.text   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abfrage des Status und Warten auf COMPLETED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_status = ('<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" '\n",
    "               'xmlns:v'+api_version+'=\"http://v'+api_version+'.export.service.data.archive.itcs.hafas.hacon.de/\">'\n",
    "               '<soapenv:Header/>'\n",
    "                    '<soapenv:Body>'\n",
    "                        '<v'+api_version+':getArchiveExportStatus>'\n",
    "                            '<exportId>' + exportId + '</exportId>'\n",
    "                        '</v'+api_version+':getArchiveExportStatus>'\n",
    "                    '</soapenv:Body>'\n",
    "              '</soapenv:Envelope>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = ''\n",
    "time.sleep(2) # initiales Warten auf Beendigung\n",
    "while status != 'COMPLETED':\n",
    "    r = requests.post(myUrl, data=xml_status)\n",
    "    #print(r, '\\n',r.text)\n",
    "    root = ET.fromstring(r.text)\n",
    "    for child in root.iter('status'):\n",
    "        #print(child.tag, child.attrib, child.text)\n",
    "        status = child.text\n",
    "        print(f'{dt.datetime.now()} Status: {status}')\n",
    "        if status != 'COMPLETED': # Pause falls Job nicht beendet (Status nicht completed d.h. in process)\n",
    "            time.sleep(20) # Pause von 20 Sekunden bis zur nächsten Abfrage des Status"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abfrage Ergebnis nach Fertigstellung des Ergebnisses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_jl = ('<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" '\n",
    "               'xmlns:v'+api_version+'=\"http://v'+api_version+'.export.service.data.archive.itcs.hafas.hacon.de/\">'\n",
    "                 '<soapenv:Header/><soapenv:Body>'\n",
    "                    '<v'+api_version+':getArchiveJourneyList>'\n",
    "                       '<exportId>' + exportId + '</exportId>'              \n",
    "                     '</v'+api_version+':getArchiveJourneyList>'\n",
    "                 '</soapenv:Body>'\n",
    "          '</soapenv:Envelope>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(myUrl, data=xml_jl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r.text)/1000000 #in Millionen Zeichen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erzeugen einer xml-Datei mit schöner Ausgabe\n",
    "(dies sollte nur bei kleineren Tests genutzt werden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ausgabe_xml = True # Einstellen ob Ausgabe gewünscht Übergabe als Papermill Parameter output_xml\n",
    "print(ausgabe_xml)\n",
    "xml_path = 'api_xml'\n",
    "xml_out = 'rt_archiv_' + startendDate + '.xml'\n",
    "try: \n",
    "    if ausgabe_xml == True:\n",
    "        dom = xml.dom.minidom.parseString(r.text)\n",
    "        pretty_xml_as_string = dom.toprettyxml()\n",
    "        #jl = open('api_xml/rt_archiv_' + dt.datetime.now().strftime('%Y%m%d') + '.xml', 'w')\n",
    "\n",
    "        jl = open(os.path.join(xml_path, xml_out), 'w')\n",
    "        print(pretty_xml_as_string, file = jl)\n",
    "        jl.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ablage als tarfile gezippt und Löschen der großen xml-Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml_out = 'rt_archiv_2023-11-03.xml'\n",
    "# Create a new tar.gz file\n",
    "tar_gz = xml_out + '.tar.gz'\n",
    "with tarfile.open(os.path.join(xml_path, tar_gz), 'w:gz') as archive:\n",
    "    # Add files to the tarball\n",
    "    archive.add(os.path.join(xml_path, xml_out), arcname= xml_out)\n",
    "                \n",
    "os.remove(os.path.join(xml_path, xml_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsen des xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ermitteln der Fahrtenzahl bisheriger Ansatz\n",
    "def import_rt_xml_to_df(xml):\n",
    "    format_date = '%Y-%m-%dT%H:%M:%S'\n",
    "    lop = []\n",
    "    \n",
    "    # create element tree object \n",
    "    tree = ET.parse(xml)\n",
    "    \n",
    "    # get root element \n",
    "    root = tree.getroot() \n",
    "\n",
    "    for child in root.iter('archiveExportJourneyAndDetailsDto'):\n",
    "        for journey in child.iter('journey'):\n",
    "            operday = dt.datetime.strptime(rt_func.isnone(journey.find('operatingDay'))[:-6], format_date).strftime('%Y-%m-%d')\n",
    "            fnr = rt_func.isnone(journey.find('journeyID'))\n",
    "\n",
    "            journeyOperator = rt_func.isnone(journey.find('journeyOperator'))\n",
    "            ex_lineid = rt_func.isnone(journey.find('externalLineId'))\n",
    "            ex_linid_short = ':'.join(ex_lineid.split(':')[0:3])\n",
    "            lineshortname = rt_func.isnone(journey.find('lineShortName'))\n",
    "            destination = rt_func.isnone(journey.find('destination'))\n",
    "\n",
    "            hasRealtime = rt_func.isnone(journey.find('hasRealtime'))\n",
    "\n",
    "            journeycancelled = rt_func.isnone(journey.find('journeyCancelled')).capitalize()\n",
    "            ts_reported_cancelled = rt_func.isnone(journey.find('lastTimestampJourneyCancellationReported'))\n",
    "            reported_cancelled = True if len(ts_reported_cancelled) > 0 else False\n",
    "            cancelled_kum = True if str(reported_cancelled) == 'True' else True if str(journeycancelled) == 'True' else False\n",
    "            \n",
    "            lop.append([operday, fnr, destination, hasRealtime, journeyOperator, ex_lineid, ex_linid_short, lineshortname, \\\n",
    "                        reported_cancelled, journeycancelled, ts_reported_cancelled, cancelled_kum])\n",
    "            \n",
    "            child.clear()\n",
    "\n",
    "    df_fahrten = pd.DataFrame(lop, columns=['datum','fnr' ,'destination','hasRealtime' ,'vu', 'lineid', 'lineid_short', 'lineshort', \\\n",
    "                                            'reported_cancelled', 'journey_cancelled','ts_reported_cancelled' ,'cancelled_kum' ])\n",
    "    return df_fahrten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schreiben der Tabellen nach Duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiales Anlegen der DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiales Anlegen\n",
    "with duckdb.connect('db/rt.db') as con:\n",
    "    con.install_extension(\"spatial\")\n",
    "    con.load_extension(\"spatial\")\n",
    "    con.sql(\"CREATE or replace TABLE fahrten AS SELECT * FROM df_fahrten\")\n",
    "    con.sql(\"CREATE OR REPLACE TABLE lin_dm AS SELECT * FROM df_lin_dm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anfügen von Datensätzen\n",
    "https://duckdb.org/docs/api/python/data_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_import = 'rt_archiv_2023-11-02.xml'\n",
    "xml_import_path = 'api_xml'\n",
    "\n",
    "tar_gz = xml_import + '.tar.gz'\n",
    "\n",
    "if os.path.exists(os.path.join(xml_import_path, tar_gz)):\n",
    "    with tarfile.open(os.path.join(xml_import_path, tar_gz), 'r:gz') as tar:\n",
    "        # Extract all files to the specified directory    \n",
    "        tar.extractall(xml_import_path)\n",
    "else:\n",
    "    print('no tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬─────────────┐\n",
      "│   datum    │ fartehn_tag │\n",
      "│  varchar   │    int64    │\n",
      "├────────────┼─────────────┤\n",
      "│ 2023-11-01 │       17224 │\n",
      "│ 2023-11-02 │       17262 │\n",
      "│ 2023-11-03 │       17228 │\n",
      "│ 2023-11-04 │       10676 │\n",
      "│ 2023-11-05 │        7066 │\n",
      "│ 2023-11-06 │       17377 │\n",
      "│ 2023-11-07 │       17437 │\n",
      "│ 2023-11-08 │       17377 │\n",
      "│ 2023-11-09 │       17417 │\n",
      "│ 2023-11-10 │       17231 │\n",
      "│ 2023-11-11 │       10938 │\n",
      "│ 2023-11-12 │        7199 │\n",
      "│ 2023-11-13 │       17618 │\n",
      "│ 2023-11-14 │       17572 │\n",
      "│ 2023-11-15 │       17577 │\n",
      "│ 2023-11-16 │       17586 │\n",
      "│ 2023-11-17 │       17275 │\n",
      "├────────────┴─────────────┤\n",
      "│ 17 rows        2 columns │\n",
      "└──────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xml_import = 'rt_archiv_2023-11-17.xml'\n",
    "xml_import_path = 'api_xml'\n",
    "\n",
    "tar_gz = xml_import + '.tar.gz'\n",
    "\n",
    "if os.path.exists(os.path.join(xml_import_path, tar_gz)):\n",
    "    with tarfile.open(os.path.join(xml_import_path, tar_gz), 'r:gz') as tar:\n",
    "        # Extract all files to the specified directory    \n",
    "        tar.extractall(xml_import_path)\n",
    "else:\n",
    "    print('no tar.gz')\n",
    "\n",
    "df_rt_app = import_rt_xml_to_df(os.path.join(xml_import_path, xml_import))\n",
    "\n",
    "with duckdb.connect('db/rt.db') as con:\n",
    "    con.install_extension(\"spatial\")\n",
    "    con.load_extension(\"spatial\")\n",
    "    con.sql(\"INSERT INTO fahrten SELECT * FROM df_rt_app\")\n",
    "    print(con.sql('select datum, count(datum) fartehn_tag from fahrten group by datum order by datum;'))\n",
    "\n",
    "\n",
    "with tarfile.open(os.path.join(xml_import_path, tar_gz), 'w:gz') as archive:\n",
    "    # Add files to the tarball\n",
    "    archive.add(os.path.join(xml_import_path, xml_import), arcname= xml_import)\n",
    "                \n",
    "os.remove(os.path.join(xml_import_path, xml_import))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────┬─────────────┐\n",
      "│   datum    │ fartehn_tag │\n",
      "│  varchar   │    int64    │\n",
      "├────────────┼─────────────┤\n",
      "│ 2023-11-01 │       17224 │\n",
      "│ 2023-11-02 │       17262 │\n",
      "│ 2023-11-03 │       17228 │\n",
      "│ 2023-11-04 │       10676 │\n",
      "│ 2023-11-05 │        7066 │\n",
      "│ 2023-11-06 │       17377 │\n",
      "│ 2023-11-07 │       17437 │\n",
      "│ 2023-11-08 │       17377 │\n",
      "│ 2023-11-09 │       17417 │\n",
      "│ 2023-11-10 │       17231 │\n",
      "├────────────┴─────────────┤\n",
      "│ 10 rows        2 columns │\n",
      "└──────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect('db/rt.db') as con:\n",
    "    print(con.sql('select datum, count(datum) fartehn_tag from fahrten group by datum order by datum;'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with duckdb.connect('db/rt.db') as con:\n",
    "#    con.sql(\"delete from fahrten where datum >= '2023-11-11'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┐\n",
      "│  name   │\n",
      "│ varchar │\n",
      "├─────────┤\n",
      "│ fahrten │\n",
      "│ lin_dm  │\n",
      "└─────────┘\n",
      "\n",
      "┌───────────────────────┬─────────────┬─────────┬─────────┬─────────┬───────┐\n",
      "│      column_name      │ column_type │  null   │   key   │ default │ extra │\n",
      "│        varchar        │   varchar   │ varchar │ varchar │ varchar │ int32 │\n",
      "├───────────────────────┼─────────────┼─────────┼─────────┼─────────┼───────┤\n",
      "│ datum                 │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ fnr                   │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ destination           │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ hasRealtime           │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ vu                    │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ lineid                │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ lineid_short          │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ lineshort             │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ reported_cancelled    │ BOOLEAN     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ journey_cancelled     │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ ts_reported_cancelled │ VARCHAR     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "│ cancelled_kum         │ BOOLEAN     │ YES     │ NULL    │ NULL    │  NULL │\n",
      "├───────────────────────┴─────────────┴─────────┴─────────┴─────────┴───────┤\n",
      "│ 12 rows                                                         6 columns │\n",
      "└───────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with duckdb.connect('db/rt.db') as con:\n",
    "    print(con.sql('show tables;'))\n",
    "    print(con.sql('describe fahrten;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect('db/rt.db') as con:\n",
    "    con.install_extension(\"spatial\")\n",
    "    con.load_extension(\"spatial\")\n",
    "    df_false_rt = con.sql(\"SELECT * FROM fahrten WHERE hasRealtime = False ORDER BY lineid\").df()\n",
    "    df_rt = con.sql(\"SELECT * FROM fahrten\").df()\n",
    "    df_fahrten_buendel = con.sql(\"SELECT * FROM fahrten LEFT JOIN lin_dm ON fahrten.lineid_short = lin_dm.dlid ORDER BY lineid\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1118        de:VBN:1\n",
       "336        de:VBN:10\n",
       "1881      de:VBN:101\n",
       "1641      de:VBN:102\n",
       "3721     de:VBN:1020\n",
       "            ...     \n",
       "1521      de:VBN:S35\n",
       "10433     de:VBN:VNN\n",
       "1104     de:hvv:RB33\n",
       "563      de:hvv:RB41\n",
       "508       de:hvv:RE4\n",
       "Name: lineid_short, Length: 652, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = df_rt.lineid_short.drop_duplicates().sort_values()\n",
    "lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnr</th>\n",
       "      <th>cancelled_kum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>17224</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02</th>\n",
       "      <td>17262</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-03</th>\n",
       "      <td>17228</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-04</th>\n",
       "      <td>10676</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-05</th>\n",
       "      <td>7066</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>17377</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-07</th>\n",
       "      <td>17437</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-08</th>\n",
       "      <td>17377</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>17417</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10</th>\n",
       "      <td>17231</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-11</th>\n",
       "      <td>10938</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-12</th>\n",
       "      <td>7199</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13</th>\n",
       "      <td>17618</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-14</th>\n",
       "      <td>17572</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-15</th>\n",
       "      <td>17577</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-16</th>\n",
       "      <td>17586</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-17</th>\n",
       "      <td>17275</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fnr  cancelled_kum\n",
       "datum                           \n",
       "2023-11-01  17224            128\n",
       "2023-11-02  17262             93\n",
       "2023-11-03  17228             70\n",
       "2023-11-04  10676            180\n",
       "2023-11-05   7066             98\n",
       "2023-11-06  17377            146\n",
       "2023-11-07  17437            123\n",
       "2023-11-08  17377            106\n",
       "2023-11-09  17417            114\n",
       "2023-11-10  17231            145\n",
       "2023-11-11  10938            207\n",
       "2023-11-12   7199             84\n",
       "2023-11-13  17618            239\n",
       "2023-11-14  17572            256\n",
       "2023-11-15  17577            239\n",
       "2023-11-16  17586            655\n",
       "2023-11-17  17275            334"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rt[['datum', 'cancelled_kum', 'fnr']].groupby('datum').agg({'fnr': 'count', 'cancelled_kum':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fnr</th>\n",
       "      <th>cancelled_kum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-03</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-04</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-05</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-06</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-07</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-08</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-09</th>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-10</th>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-11</th>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-12</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-13</th>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-14</th>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-15</th>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-16</th>\n",
       "      <td>655</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-17</th>\n",
       "      <td>334</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fnr  cancelled_kum\n",
       "datum                         \n",
       "2023-11-01  128            128\n",
       "2023-11-02   93             93\n",
       "2023-11-03   70             70\n",
       "2023-11-04  180            180\n",
       "2023-11-05   98             98\n",
       "2023-11-06  146            146\n",
       "2023-11-07  123            123\n",
       "2023-11-08  106            106\n",
       "2023-11-09  114            114\n",
       "2023-11-10  145            145\n",
       "2023-11-11  207            207\n",
       "2023-11-12   84             84\n",
       "2023-11-13  239            239\n",
       "2023-11-14  256            256\n",
       "2023-11-15  239            239\n",
       "2023-11-16  655            655\n",
       "2023-11-17  334            334"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rt[df_rt.cancelled_kum == True][['datum', 'cancelled_kum', 'fnr']].groupby('datum')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgabe der Werte im Fahrtverlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "format = '%Y-%m-%dT%H:%M:%S'\n",
    "log_verlauf_arr = []\n",
    "\n",
    "root = ET.fromstring(r.text)\n",
    "for child in root.iter('archiveExportJourneyAndDetailsDto'):\n",
    "    for journey in child.iter('journey'):\n",
    "        rt = rt_func.isnone(journey.find('hasRealtime'))\n",
    "        deviceid = rt_func.isnone(journey.find('deviceId'))\n",
    "        fnr = rt_func.isnone(journey.find('journeyID'))\n",
    "        lineshortname = str(rt_func.isnone(journey.find('lineShortName'))).strip()\n",
    "        ex_lineid = rt_func.isnone(journey.find('externalLineId'))\n",
    "        journeyOperator = rt_func.isnone(journey.find('journeyOperator'))\n",
    "        operday = dt.datetime.strptime(rt_func.isnone(journey.find('operatingDay'))[:-6], format).strftime('%Y-%m-%d')\n",
    "        ts_reported_cancelled = rt_func.isnone(journey.find('lastTimestampJourneyCancellationReported'))\n",
    "        reported_cancelled = True if len(ts_reported_cancelled) > 0 else False\n",
    "\n",
    "    for details in child.iter('details'):\n",
    "        index = rt_func.isnone(details.find('index'))\n",
    "        for ddelay in details.iter('departureDelay'):\n",
    "            dep_del = rt_func.isnone_delay(ddelay.find('delay'))\n",
    "\n",
    "        for adelay in details.iter('arrivalDelay'):\n",
    "            arr_del = rt_func.isnone_delay(adelay.find('delay'))\n",
    "        \n",
    "        canc = rt_func.isnone(details.find('cancelled'))\n",
    "        \n",
    "        additional =  rt_func.isnone(details.find('additional'))\n",
    "\n",
    "        for station in details.iter('station'):\n",
    "            lat = int(station.find('latitude').text)/1000000\n",
    "            lon = int(station.find('longitude').text)/1000000\n",
    "            snr = station.find('stationExternalNumber').text\n",
    "            if station.find('stationName') is not None:\n",
    "                sname = station.find('stationName').text\n",
    "            else:\n",
    "                sname = '-'\n",
    "        \n",
    "        for dschedule in details.iter('scheduleDepartureTime'):\n",
    "            dschedtime= dschedule.find('scheduleTime')\n",
    "            if dschedtime is not None:\n",
    "                dschedtime = dt.datetime.strptime(dschedtime.text[:-6], format).strftime('%Y%m%d%H%M%S') #Umwandlung der Zeitformat da in 3.6 kein ISO-Format vorhanden\n",
    "            else:\n",
    "                dschedtime =''\n",
    "        for aschedule in details.iter('scheduleArrivalTime'):\n",
    "            aschedtime = aschedule.find('scheduleTime')\n",
    "            if aschedtime is not None:\n",
    "                aschedtime = dt.datetime.strptime(aschedtime.text[:-6], format).strftime('%Y%m%d%H%M%S')\n",
    "            else: \n",
    "                aschedtime =''\n",
    "        \n",
    "        # Schreiben in die Datei log_verlauf\n",
    "        #print(operday, journeyOperator, deviceid, lineshortname, ex_lineid, fnr, index, rt, dschedtime, aschedtime, \\\n",
    "        #      dep_del, arr_del, snr, sname, lat, lon, canc, additional, reported_cancelled,ts_reported_cancelled,file=log_verlauf, sep=';')\n",
    "        log_verlauf_arr.append([operday, journeyOperator, deviceid, lineshortname, ex_lineid, \n",
    "                                fnr, index, rt, dschedtime, aschedtime, dep_del, arr_del, snr, sname, lat, lon, canc, additional, ts_reported_cancelled, reported_cancelled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sort = pd.DataFrame(log_verlauf_arr, columns= ['tag', 'journeyOperator', 'deviceid', 'linie', 'externallinid', 'fahrtnummer', 'index', 'realtime', 'ab_soll', \n",
    "                                  'an_soll', 'ab_delay', 'an_delay', 'stationnumber', 'stationname', 'lat', 'lon', 'cancelled', 'additional', 'ts_reported_cancelled', 'reported_cancelled'])\n",
    "\n",
    "log_sort['index'] = log_sort['index'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rausfiltern der Fahrten ohne Fahrtnummer (aufgetreten 9/2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sort = log_sort[~(log_sort.fahrtnummer == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sort['fahrtnummer'] = log_sort['fahrtnummer'].astype(np.int32)\n",
    "log_sort['stationnumber'] = log_sort['stationnumber'].astype(np.int32)\n",
    "log_sort['linie'] = log_sort['linie'].astype(str)\n",
    "log_sort['stationname'] = log_sort['stationname'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export als Parquet\n",
    "#log_sort.astype({'linie':'string'}).to_parquet('log/verlauf.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sort['ab_soll'] = log_sort.apply(lambda x: rt_func.format_zeit(x['ab_soll']), axis=1)\n",
    "log_sort['an_soll'] = log_sort.apply(lambda x: rt_func.format_zeit(x['an_soll']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausgabe der Werte je Fahrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fahrt_array = []\n",
    "root = ET.fromstring(r.text)\n",
    "for child in root.iter('archiveExportJourneyAndDetailsDto'):\n",
    "    for journey in child.iter('journey'):\n",
    "        rt = rt_func.isnone(journey.find('hasRealtime'))\n",
    "        deviceid = rt_func.isnone(journey.find('deviceId'))\n",
    "        fnr = rt_func.isnone(journey.find('journeyID'))\n",
    "        lineshortname = rt_func.isnone(journey.find('lineShortName'))\n",
    "        ex_lineid = rt_func.isnone(journey.find('externalLineId'))\n",
    "        dlid_pre = ex_lineid.split(':')[0:3]\n",
    "        dlid = ':'.join(dlid_pre)\n",
    "        dest = rt_func.isnone(journey.find('destination'))\n",
    "        operday = dt.datetime.strptime(rt_func.isnone(journey.find('operatingDay'))[:-6], format).strftime('%Y-%m-%d')\n",
    "        op = rt_func.isnone(journey.find('journeyOperator'))\n",
    "        cancelled = rt_func.isnone(journey.find('journeyCancelled'))\n",
    "        lastupdate = rt_func.isnone(journey.find('lastJourneyDetailsUpdateTimestamp'))\n",
    "        vehicletypeschedule = rt_func.isnone(journey.find('vehicleTypeSchedule'))\n",
    "        vehicletyperealtime = rt_func.isnone(journey.find('vehicleTypeRealtime'))\n",
    "        ts_reported_cancelled = rt_func.isnone(journey.find('lastTimestampJourneyCancellationReported'))\n",
    "        reported_cancelled = True if len(ts_reported_cancelled) > 0 else False\n",
    "        \n",
    "        journeyRtType = rt_func.isnone(journey.find('journeyRtType'))\n",
    "        try:\n",
    "            lastupdate = dt.datetime.fromtimestamp(int(lastupdate)/1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        except:\n",
    "            continue\n",
    "        distance = rt_func.isnone(journey.find('distanceSchedule'))\n",
    "        \n",
    "        if journey.find('maximumDelay'):\n",
    "            #print(fnr, day)\n",
    "            for maxdelay in journey.iter('maximumDelay'):\n",
    "                #print(maxdelay.find('delay'))\n",
    "                maxd = rt_func.isnone(maxdelay.find('delay'))\n",
    "        else:\n",
    "            maxd=''\n",
    "        \n",
    "        if journey.find('departureDelay'):\n",
    "            #print(fnr, day)\n",
    "            for depdelay in journey.iter('departureDelay'):\n",
    "                ddel = rt_func.isnone(depdelay.find('delay'))\n",
    "        else:\n",
    "            ddel=''\n",
    "        \n",
    "        if journey.find('arrivalDelay'):\n",
    "            #print(fnr, day)\n",
    "            for arrdelay in journey.iter('arrivalDelay'):\n",
    "                adel = rt_func.isnone(arrdelay.find('delay'))\n",
    "        else:\n",
    "            adel=''\n",
    "        \n",
    "        if journey.find('minimumDelay'):\n",
    "            #print(fnr, day)\n",
    "            for mindelay in journey.iter('minimumDelay'):\n",
    "                mind = rt_func.isnone(mindelay.find('delay'))\n",
    "        else:\n",
    "            mind=''\n",
    "        \n",
    "        if journey.find('realArrivalTime'):\n",
    "            #print(fnr, day)\n",
    "            for realarrival in journey.iter('realArrivalTime'):\n",
    "                rat = dt.datetime.strptime(rt_func.isnone(realarrival.find('realTime'))[:-6], format).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            rat=''        \n",
    "        \n",
    "        if journey.find('realDepartureTime'):\n",
    "            for realdeparture in journey.iter('realDepartureTime'):\n",
    "                rdt = dt.datetime.strptime(rt_func.isnone(realdeparture.find('realTime'))[:-6], format).strftime('%Y-%m-%d %H:%M:%S')                \n",
    "        else:\n",
    "            rdt=''\n",
    "\n",
    "        if journey.find('scheduleDepartureTime'):\n",
    "            for realdeparture in journey.iter('scheduleDepartureTime'):\n",
    "                sdt = dt.datetime.strptime(rt_func.isnone(realdeparture.find('scheduleTime'))[:-6], format).strftime('%Y-%m-%d %H:%M:%S')                \n",
    "        else:\n",
    "            sdt=''\n",
    "            \n",
    "        if journey.find('scheduleArrivalTime'):\n",
    "            for realdeparture in journey.iter('scheduleArrivalTime'):\n",
    "                sat = dt.datetime.strptime(rt_func.isnone(realdeparture.find('scheduleTime'))[:-6], format)\\\n",
    "                .strftime('%Y-%m-%d %H:%M:%S')                \n",
    "        else:\n",
    "            sat=''       \n",
    "        \n",
    "        if journey.find('scheduleDepartureStation'):\n",
    "            for dep_station in journey.iter('scheduleDepartureStation'):\n",
    "                sdst = rt_func.isnone(dep_station.find('stationName'))               \n",
    "        else:\n",
    "            sdst=''\n",
    "        \n",
    "        if journey.find('scheduleArrivalStation'):\n",
    "            for arr_station in journey.iter('scheduleArrivalStation'):\n",
    "                sast = rt_func.isnone(arr_station.find('stationName'))               \n",
    "        else:\n",
    "            sast=''\n",
    "        fahrt_array.append([lineshortname, ex_lineid, operday, fnr, rt, op, dest, mind, maxd,  cancelled, lastupdate, \\\n",
    "              distance, sdt, sat, rdt, rat, dlid,sdst, sast,ddel, adel, deviceid, journeyRtType, vehicletypeschedule, vehicletyperealtime, \\\n",
    "                reported_cancelled, ts_reported_cancelled])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.11.0 ('geo_311')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dcfa513e1bebd633c31802f439dbc67afc7b6eca02dfa4380fc98826b2b9354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
