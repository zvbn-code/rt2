{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abfrage Schnittstelle und Ablage in DuckDBzum Hafas Echtzeit-Archiv Produktiv / Demo-System / Ablage in Parquet\n",
    "\n",
    "Stand: 09.09.2024\n",
    "\n",
    "#### Aufgaben\n",
    "- Schema XML V14 Produktiv https://fahrplaner.vbn.de/archive/services/archiveExportService/v14?wsdl \n",
    "- Schema XML V15 demo https://vbn.demo.hafas.de/archive/services/archiveExportService/v15?wsdl\n",
    "- Dokumentation unter docs/\n",
    "- Einbauen Fahrt Start ende scheduleDepartureStation scheduleDepartureTime bzw. Arrival"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import datetime as dt\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "\n",
    "import tarfile\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import duckdb\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "from sqlalchemy import create_engine #als Alternative zu Mysql pyscopg2 Connector\n",
    "from sqlalchemy import text\n",
    "\n",
    "from importlib import reload\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rt_archiv_func_08' from '/home/zvbn/python/rt2/rt_archiv_func_08.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys; sys.path.append('/home/zvbn/python/rt2')\n",
    "import para\n",
    "import rt_archiv_func_08 as rt_func #Import der benutzerdefinierten Funktionen\n",
    "reload(rt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufrufen der SOAP-Abfrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_xml(api_version, xml_request, xml_out, myUrl):\n",
    "    #Zugriff auf Hafas RT Archiv Produktiv System und Zugriffsschlüssel \n",
    "\n",
    "    req_ini = requests.post(myUrl, data=xml_request)\n",
    "    root = ET.fromstring(req_ini.text)\n",
    "    print(req_ini.text)\n",
    "    \n",
    "    #Ermitteln der Export ID\n",
    "    for child in root.iter('exportId'):\n",
    "        print(child.tag, child.attrib, child.text)\n",
    "        exportId = child.text\n",
    "    xml_status = f\"\"\"\n",
    "                <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n",
    "                    xmlns:v{api_version}=\"http://v{api_version}.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
    "               <soapenv:Header/>\n",
    "                    <soapenv:Body>\n",
    "                        <v{api_version}:getArchiveExportStatus>\n",
    "                            <exportId>{exportId}</exportId>\n",
    "                        </v{api_version}:getArchiveExportStatus>\n",
    "                    </soapenv:Body>\n",
    "              </soapenv:Envelope>\n",
    "              \"\"\"\n",
    "    #Abfragen und Warten auf Completed\n",
    "    status = ''\n",
    "    time.sleep(2) # initiales Warten auf Beendigung\n",
    "    while status != 'COMPLETED':\n",
    "        r = requests.post(myUrl, data=xml_status)\n",
    "        #print(r, '\\n',r.text)\n",
    "        root = ET.fromstring(r.text)\n",
    "        for child in root.iter('status'):\n",
    "            #print(child.tag, child.attrib, child.text)\n",
    "            status = child.text\n",
    "            print(f'{dt.datetime.now()} Status: {status}')\n",
    "            if status != 'COMPLETED': # Pause falls Job nicht beendet (Status nicht completed d.h. in process)\n",
    "                time.sleep(10) # Pause von 20 Sekunden bis zur nächsten Abfrage des Status\n",
    "    \n",
    "    # Afrage nach Beendigung Journey List\n",
    "\n",
    "    xml_jl = ('<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" '\n",
    "               'xmlns:v'+str(api_version)+'=\"http://v'+str(api_version)+'.export.service.data.archive.itcs.hafas.hacon.de/\">'\n",
    "                 '<soapenv:Header/><soapenv:Body>'\n",
    "                    '<v'+str(api_version)+':getArchiveJourneyList>'\n",
    "                       '<exportId>' + exportId + '</exportId>'              \n",
    "                     '</v'+str(api_version)+':getArchiveJourneyList>'\n",
    "                 '</soapenv:Body>'\n",
    "          '</soapenv:Envelope>')\n",
    "    \n",
    "    rj = requests.post(myUrl, data=xml_jl)\n",
    "\n",
    "    #Ausgabe des Ergebnis XML Journey\n",
    "    dom = xml.dom.minidom.parseString(rj.text)\n",
    "    pretty_xml_as_string = dom.toprettyxml()\n",
    "    \n",
    "    jl = open(os.path.join(xml_out), 'w')\n",
    "    print(pretty_xml_as_string, file = jl)\n",
    "    print(os.path.join(xml_out), 'gespeichert')\n",
    "\n",
    "    jl.close()\n",
    "\n",
    "    #Ausgabe des Ergebnis XML Textmessage, werden aber in der Version wohl nicht unterstützt\n",
    "    #dom = xml.dom.minidom.parseString(tj.text)\n",
    "    #pretty_xml_as_string = dom.toprettyxml()\n",
    "    \n",
    "    # jl = open(xml_out, 'w')\n",
    "    # print(pretty_xml_as_string, file = jl)\n",
    "    # print(xml_out, 'gespeichert')\n",
    "\n",
    "    # jl.close()\n",
    "\n",
    "    # Afrage nach Beendigung Text Matrix ab Version 15, Textmessage list, unklar was es bringt\n",
    "    # if api_version >= 15:\n",
    "    #     xml_tl = f\"\"\"\n",
    "    #             <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n",
    "    #             xmlns:v{api_version}=\"http://v{api_version}.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
    "    #                 <soapenv:Header/><soapenv:Body>\n",
    "    #                     <v{api_version}:getArchiveTextmesssageList>\n",
    "    #                     <exportId>{exportId}</exportId>            \n",
    "    #                     </v{api_version}:getArchiveTextmesssageList>\n",
    "    #                 </soapenv:Body>\n",
    "    #         </soapenv:Envelope>\n",
    "    #         \"\"\"\n",
    "    #     print(xml_tl)\n",
    "    #     tj = requests.post(myUrl, data=xml_tl)\n",
    "    #     #Ausgabe des Ergebnis XML Journey\n",
    "    #     dom = xml.dom.minidom.parseString(tj.text)\n",
    "    #     pretty_xml_as_string = dom.toprettyxml()\n",
    "    #     xml_out_ml = 'out/ml.xml'\n",
    "    #     fml = open(os.path.join(xml_out_ml), 'w')\n",
    "    #     print(pretty_xml_as_string, file = fml)\n",
    "    #     print(os.path.join(xml_out_ml), 'ML gespeichert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import xml Fahrten > Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_rt_xml_to_df_fahrten(xml_file):\n",
    "    format_date = '%Y-%m-%dT%H:%M:%S'\n",
    "    lop = []\n",
    "    \n",
    "    # create element tree object \n",
    "    tree = ET.parse(xml_file)\n",
    "    \n",
    "    # get root element \n",
    "    root = tree.getroot() \n",
    "\n",
    "    for child in root.iter('archiveExportJourneyAndDetailsDto'):\n",
    "        for journey in child.iter('journey'):\n",
    "\n",
    "            #Ermitteln der Feldinhalte\n",
    "            deviceid = rt_func.isnone(journey.find('deviceId'))\n",
    "            operday = dt.datetime.strptime(rt_func.isnone(journey.find('operatingDay'))[:-6], format_date).strftime('%Y-%m-%d')\n",
    "            fnr = rt_func.isnone(journey.find('journeyID'))\n",
    "\n",
    "            deviceId = rt_func.isnone(journey.find('deviceId'))\n",
    "            clientId = rt_func.split_deviceid(journey.find('deviceId'))            \n",
    "\n",
    "            journeyOperator = rt_func.isnone(journey.find('journeyOperator'))\n",
    "            ex_lineid = rt_func.isnone(journey.find('externalLineId'))\n",
    "            ex_linid_short = ':'.join(ex_lineid.split(':')[0:3])\n",
    "            lineshortname = rt_func.isnone(journey.find('lineShortName'))\n",
    "            destination = rt_func.isnone(journey.find('destination'))\n",
    "\n",
    "            hasRealtime = rt_func.isnone_boolean(journey.find('hasRealtime'))\n",
    "            realtimeHasEverBeenReported = rt_func.isnone_boolean(journey.find('realtimeHasEverBeenReported'))\n",
    "            journeyRtType = rt_func.isnone(journey.find('journeyRtType'))            \n",
    "\n",
    "            journeycancelled = rt_func.isnone(journey.find('journeyCancelled')).capitalize()\n",
    "            ts_reported_cancelled = rt_func.isnone(journey.find('lastTimestampJourneyCancellationReported'))\n",
    "            reported_cancelled = True if len(ts_reported_cancelled) > 0 else False\n",
    "            cancelled_kum = True if str(reported_cancelled) == 'True' else True if str(journeycancelled) == 'True' else False\n",
    "\n",
    "            #Ermitteln FahrtStartEnde\n",
    "            for sub in journey.iter('scheduleDepartureTime'):\n",
    "                fahrtstarttime = rt_func.isnone_delay(sub.find('scheduleTime'))\n",
    "            for sub in journey.iter('scheduleArrivalTime'):\n",
    "                fahrtendtime = rt_func.isnone_delay(sub.find('scheduleTime'))\n",
    "            for sub in journey.iter('scheduleDepartureStation'):\n",
    "                fahrtstartstationname = rt_func.isnone_delay(sub.find('stationName'))\n",
    "                fahrtstartstationdhid = rt_func.isnone_delay(sub.find('dhid'))\n",
    "            for sub in journey.iter('scheduleArrivalStation'):\n",
    "                fahrtendstationname = rt_func.isnone_delay(sub.find('stationName'))\n",
    "                fahrtendstationdhid = rt_func.isnone_delay(sub.find('dhid'))\n",
    "\n",
    "            \n",
    "            lop.append([operday, fnr, destination, hasRealtime, realtimeHasEverBeenReported,journeyOperator, ex_lineid, ex_linid_short, lineshortname, \\\n",
    "                        reported_cancelled, journeycancelled, ts_reported_cancelled, cancelled_kum, deviceId, clientId, journeyRtType, \\\n",
    "                            fahrtstarttime, fahrtstartstationname, fahrtstartstationdhid, fahrtendtime, fahrtendstationname, fahrtendstationdhid])\n",
    "            \n",
    "            child.clear()\n",
    "\n",
    "    df_fahrten = pd.DataFrame(lop, columns=['datum','fnr' ,'destination','hasRealtime','realtimeHasEverBeenReported','vu', 'lineid', 'lineid_short', 'lineshort', \\\n",
    "                                            'reported_cancelled', 'journey_cancelled','ts_reported_cancelled' ,'cancelled_kum', 'deviceid', \\\n",
    "                                                'clientid', 'journeyrttype', 'fahrtstarttime', 'fahrtstartstationname', 'fahrtstartstationdhid',\\\n",
    "                                                      'fahrtendtime', 'fahrtendstationname', 'fahrtendstationdhid'])\n",
    "    return df_fahrten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import xml Verlauf > Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_rt_xml_to_df_verlauf(xml_file):\n",
    "    format_dt = '%Y-%m-%dT%H:%M:%S'\n",
    "    lop = []\n",
    "\n",
    "    # create element tree object \n",
    "    tree = ET.parse(xml_file)\n",
    "    \n",
    "    # get root element \n",
    "    root = tree.getroot() \n",
    "    for child in root.iter('archiveExportJourneyAndDetailsDto'):\n",
    "        for journey in child.iter('journey'):\n",
    "            has_rt = rt_func.isnone(journey.find('hasRealtime'))\n",
    "            \n",
    "            deviceid = rt_func.isnone(journey.find('deviceId'))\n",
    "            fnr = rt_func.isnone(journey.find('journeyID'))\n",
    "            lineshortname = str(rt_func.isnone(journey.find('lineShortName'))).strip()\n",
    "            ex_lineid = rt_func.isnone(journey.find('externalLineId'))\n",
    "            journeyOperator = rt_func.isnone(journey.find('journeyOperator'))\n",
    "            operday = dt.datetime.strptime(rt_func.isnone(journey.find('operatingDay'))[:-6], format_dt).strftime('%Y-%m-%d')\n",
    "            ts_reported_cancelled = rt_func.isnone(journey.find('lastTimestampJourneyCancellationReported'))\n",
    "            reported_cancelled = True if len(ts_reported_cancelled) > 0 else False\n",
    "\n",
    "        for details in child.iter('details'):\n",
    "            index = rt_func.isnone(details.find('index'))\n",
    "            for ddelay in details.iter('departureDelay'):\n",
    "                dep_del = rt_func.isnone_delay(ddelay.find('delay'))\n",
    "\n",
    "            for adelay in details.iter('arrivalDelay'):\n",
    "                arr_del = rt_func.isnone_delay(adelay.find('delay'))\n",
    "            \n",
    "            canc = rt_func.isnone(details.find('cancelled'))\n",
    "            \n",
    "            additional =  rt_func.isnone(details.find('additional'))\n",
    "\n",
    "            for station in details.iter('station'):\n",
    "                lat = int(station.find('latitude').text)/1000000\n",
    "                lon = int(station.find('longitude').text)/1000000\n",
    "                station_nr = station.find('stationExternalNumber').text\n",
    "                if station.find('stationName') is not None:\n",
    "                    station_name = station.find('stationName').text\n",
    "                else:\n",
    "                    station_name = '-'\n",
    "            \n",
    "            for dschedule in details.iter('scheduleDepartureTime'):\n",
    "                dschedtime= dschedule.find('scheduleTime')\n",
    "                if dschedtime is not None:\n",
    "                    dschedtime = dt.datetime.strptime(dschedtime.text[:-6], format_dt).strftime('%Y%m%d%H%M%S') #Umwandlung der Zeitformat da in 3.6 kein ISO-Format vorhanden\n",
    "                else:\n",
    "                    dschedtime =''\n",
    "            for aschedule in details.iter('scheduleArrivalTime'):\n",
    "                aschedtime = aschedule.find('scheduleTime')\n",
    "                if aschedtime is not None:\n",
    "                    aschedtime = dt.datetime.strptime(aschedtime.text[:-6], format_dt).strftime('%Y%m%d%H%M%S')\n",
    "                else: \n",
    "                    aschedtime =''\n",
    "\n",
    "            lop.append([operday, journeyOperator, deviceid, lineshortname, ex_lineid, \n",
    "                                    fnr, index, has_rt, dschedtime, aschedtime, dep_del, arr_del, station_nr, station_name, lat, lon, canc, additional, \n",
    "                                    ts_reported_cancelled, reported_cancelled])\n",
    "    \n",
    "    df_verlauf = pd.DataFrame(lop, columns=['operday','journeyOperator' ,'deviceid','lineshortname' ,'ex_lineid', 'fnr', 'index', 'has_rt', \n",
    "                                            'dschedtime', 'aschedtime','dep_del' ,'arr_del', 'station_nr', 'station_name', 'lat', 'lon', 'canc', 'additional', \n",
    "                                            'ts_reported_cancelled', 'reported_cancelled'])\n",
    "    return df_verlauf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausgabe als formatiertes xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testen des XML mit schöner Ausgabe\n",
    "def print_pretty_xml(xml_request):\n",
    "    dom = xml.dom.minidom.parseString(xml_request)\n",
    "    pretty_xml_as_string = dom.toprettyxml()\n",
    "    print(pretty_xml_as_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xml to tar.gz\n",
    "- Packen und Löschen des Ausgangs xml Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_targz(xml_path,xml_file):\n",
    "    \"\"\"Packen des xml-files\"\"\"\n",
    "    tar_gz = xml_file + '.tar.gz'\n",
    "\n",
    "    if os.path.exists(os.path.join(xml_path, tar_gz)):\n",
    "        with tarfile.open(os.path.join(xml_path, tar_gz), 'r:gz') as tar:\n",
    "            # Extract all files to the specified directory    \n",
    "            tar.extractall(xml_path)\n",
    "    else:\n",
    "        print('no tar.gz')\n",
    "\n",
    "    with tarfile.open(os.path.join(xml_path, tar_gz), 'w:gz') as archive:\n",
    "        # Add files to the tarball\n",
    "        archive.add(os.path.join(xml_path, xml_file), arcname= xml_file)\n",
    "                    \n",
    "    os.remove(os.path.join(xml_path, xml_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umwandlung der Datentypen Fahrten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_df_fahrten(df_rt_vbn_fahrten):\n",
    "    \"\"\"Umwandlung in verwendbare Boolean Typen\"\"\"\n",
    "    df_rt_vbn_fahrten['datum'] = pd.to_datetime(df_rt_vbn_fahrten['datum'], format='%Y-%m-%d')\n",
    "    #Umwandlung be gemischten Zeitzonen manuell mit strptime\n",
    "    #df_rt_vbn_fahrten['fahrtstarttime'] = pd.to_datetime(df_rt_vbn_fahrten['fahrtstarttime'], utc=True)\n",
    "    df_rt_vbn_fahrten['journey_cancelled'] = df_rt_vbn_fahrten['journey_cancelled'].replace({'True':True,'False':False},regex=True)\n",
    "    return df_rt_vbn_fahrten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Umwandlung der Datentypen Verlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_df_verlauf(df_rt_vbn_verlauf):\n",
    "    \"\"\" Anpassung der verschiedenen Datentypen in der Datei Verlauf\"\"\"\n",
    "    df_rt_vbn_verlauf['lat'] = df_rt_vbn_verlauf['lat'].astype(float)\n",
    "    df_rt_vbn_verlauf['lon'] = df_rt_vbn_verlauf['lon'].astype(float)\n",
    "    df_rt_vbn_verlauf['dep_del'] = df_rt_vbn_verlauf['dep_del'].astype(float)\n",
    "    df_rt_vbn_verlauf['arr_del'] = df_rt_vbn_verlauf['arr_del'].astype(float)\n",
    "    df_rt_vbn_verlauf['canc'] = df_rt_vbn_verlauf['canc'].replace({'true':True,'false':False},regex=True)\n",
    "    df_rt_vbn_verlauf['has_rt'] = df_rt_vbn_verlauf['has_rt'].replace({'true':True,'false':False},regex=True)\n",
    "    df_rt_vbn_verlauf['additional'] = df_rt_vbn_verlauf['additional'].replace({'true':True,'false':False},regex=True)\n",
    "    df_rt_vbn_verlauf['reported_cancelled'] = df_rt_vbn_verlauf['reported_cancelled'].replace({'True':True,'False':False},regex=True)\n",
    "    df_rt_vbn_verlauf['index'] = df_rt_vbn_verlauf['index'].astype('Int32')\n",
    "    df_rt_vbn_verlauf['operday'] = pd.to_datetime(df_rt_vbn_verlauf['operday'], format='%Y-%m-%d')\n",
    "    df_rt_vbn_verlauf['dschedtime'] = pd.to_datetime(df_rt_vbn_verlauf['dschedtime'], format='%Y%m%d%H%M%S')\n",
    "    df_rt_vbn_verlauf['aschedtime'] = pd.to_datetime(df_rt_vbn_verlauf['aschedtime'], format='%Y%m%d%H%M%S')\n",
    "    return df_rt_vbn_verlauf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einlesen der Linienliste / Zuordnung Bündel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen aus der lokalen DM Datenbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbindung erfolgreich -lokale Datei aktualisiert\n"
     ]
    }
   ],
   "source": [
    "#Zugriff auf die lokale Datenbank auf dem Wortmann Debian Server\n",
    "\n",
    "try:\n",
    "    engine = create_engine(\"postgresql+psycopg2://postgres:\"+para.key_dm_db+\"@127.0.0.1:5432/zvbn_postgis\")\n",
    "    #conn_dm = psycopg2.connect(database='zvbn_postgis', user='postgres', password=para.key_dm_db, host = '127.0.0.1')\n",
    "    sql_lin = 'SELECT nummer AS linie, buendel, \\'\\' AS rt_operator, ebene, dlid, id \\\n",
    "        FROM basis.linien \\\n",
    "        WHERE buendel IS NOT NULL AND aktiv IS TRUE \\\n",
    "        ORDER BY buendel, ebene, nummer'\n",
    "    sql_buendel = 'SELECT * FROM basis.lin_buendel'\n",
    "    df_lin_dm =  pd.read_sql(text(sql_lin), engine.connect())\n",
    "    df_buendel = pd.read_sql(text(sql_buendel), engine.connect())\n",
    "    df_lin_dm.to_csv('input/linien_dm.csv', sep=';', index=False)\n",
    "    print('Verbindung erfolgreich -lokale Datei aktualisiert')\n",
    "except:\n",
    "    df_lin_dm = pd.read_csv('input/linien_dm.csv', sep=';') #aktuelle Zuordnung Linie zu Bündel aus DM\n",
    "    print(f'Verbindung nicht erfolgreich - Verwendung lokale Datei')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abruf XML und Erstellen Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesamt VBN\n",
    "\n",
    "- Abfagen aller Daten für einen Tag über die Externallinid (de:VBN:* und Metronomlinien mit de:hvv:) de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4: und 910 aus Cloppenburg\n",
    "- lineExternalNamePattern Abfrage über DLID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen der Abfrage für xml-Soap mit Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<lineExternalNamePattern>de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:,de:VBN-VGC:910:</lineExternalNamePattern> \n",
    "\n",
    "def def_xml_request_dlid(start, ende, api_version, clientID, matrix, lineExternalNamePattern):\n",
    "     \"\"\" Erstellen der SOAP Abfrage mit verschiedenen Parametern\"\"\"\n",
    "     if api_version >= 15:\n",
    "        options = f\"\"\"\n",
    "               <options>\n",
    "                    <includeMatrixData>{str(matrix).lower()}</includeMatrixData>\n",
    "               </options>\n",
    "               \"\"\"\n",
    "     else:\n",
    "        options = \"\"\n",
    "     \n",
    "     xml_request_dlid = f\"\"\"\n",
    "     <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:v{api_version}=\"http://v{api_version}.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
    "                    <soapenv:Header/>\n",
    "                    <soapenv:Body>\n",
    "                    <v{api_version}:createArchiveJob>\n",
    "                         <filter>\n",
    "                              <clientId>{clientID}</clientId>                    \n",
    "                              <startDate>{start}</startDate>\n",
    "                              <endDate>{ende}</endDate>\n",
    "                              <lineExternalNamePattern>{lineExternalNamePattern}</lineExternalNamePattern>            \n",
    "                              <hasRealtime>ALL</hasRealtime>\n",
    "                         </filter>\n",
    "                         {options}\n",
    "                    </v{api_version}:createArchiveJob>\n",
    "                    \n",
    "               </soapenv:Body>\n",
    "          </soapenv:Envelope>\n",
    "                    \"\"\"\n",
    "     return xml_request_dlid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:v15=\"http://v15.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
      "                    <soapenv:Header/>\n",
      "                    <soapenv:Body>\n",
      "                    <v15:createArchiveJob>\n",
      "                         <filter>\n",
      "                              <clientId>PMQmY5p9y8kmoTno</clientId>                    \n",
      "                              <startDate>2024-09-18</startDate>\n",
      "                              <endDate>2024-09-18</endDate>\n",
      "                              <lineExternalNamePattern></lineExternalNamePattern>            \n",
      "                              <hasRealtime>ALL</hasRealtime>\n",
      "                         </filter>\n",
      "                         \n",
      "               <options>\n",
      "                    <includeMatrixData>true</includeMatrixData>\n",
      "               </options>\n",
      "               \n",
      "                    </v15:createArchiveJob>\n",
      "                    \n",
      "               </soapenv:Body>\n",
      "          </soapenv:Envelope>\n",
      "                    \n"
     ]
    }
   ],
   "source": [
    "gestern = (dt.date.today() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "print(def_xml_request_dlid(start=gestern, ende=gestern, api_version=15, clientID='PMQmY5p9y8kmoTno', matrix=True, lineExternalNamePattern=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen der Abfrage für xml-Soap mit Funktion Zusatzfahrten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_xml_request_zusatz(start, ende, api_version, clientID):\n",
    "        \"\"\"Erstellen der SOAP-Anfrage für den Teil Zusatzfahrten\"\"\"\n",
    "        xml_request_zusatz_umleitung = f\"\"\"\n",
    "                                    <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n",
    "                xmlns:v{api_version}=\"http://v{api_version}.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
    "                <soapenv:Header/><soapenv:Body><v{api_version}:createArchiveJob>\n",
    "                <filter>\n",
    "                        <clientId>{clientID}</clientId>         \n",
    "                        <startDate>{start}</startDate>\n",
    "                        <endDate>{ende}</endDate>\n",
    "                        <filterJourneyRtTypeList>REALTIME_EXTRA</filterJourneyRtTypeList>\n",
    "                        <filterJourneyRtTypeList>REALTIME_EXTRA_REPLACEMENT</filterJourneyRtTypeList>\n",
    "                        <filterJourneyRtTypeList>REALTIME_EXTRA_REPORTED</filterJourneyRtTypeList>\n",
    "                        <filterJourneyRtTypeList>REALTIME_EXTRA_MAINTENANCE</filterJourneyRtTypeList>\n",
    "                        <filterJourneyRtTypeList>DEVIATION_OF_SCHEDULED</filterJourneyRtTypeList>\n",
    "                        <filterJourneyRtTypeList>DEVIATION_OF_REALTIME_EXTRA</filterJourneyRtTypeList>         \n",
    "                        <filterJourneyRtTypeList>DEVIATION_OF_REPLACEMENT</filterJourneyRtTypeList>             \n",
    "                        <filterJourneyRtTypeList>SUPPLEMENTARY</filterJourneyRtTypeList>'                \n",
    "                        <filterJourneyRtTypeList>UNKNOWN</filterJourneyRtTypeList>               \n",
    "                        <hasRealtime>ALL</hasRealtime>\n",
    "                </filter>\n",
    "                </v{api_version}:createArchiveJob></soapenv:Body></soapenv:Envelope>\n",
    "                \"\"\"\n",
    "        return xml_request_zusatz_umleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOAP Abfrage ausführen Verlauf / Fahrten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produktivsystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" xmlns:v15=\"http://v15.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
      "                    <soapenv:Header/>\n",
      "                    <soapenv:Body>\n",
      "                    <v15:createArchiveJob>\n",
      "                         <filter>\n",
      "                              <clientId>mvHU2OdQDJTwQD4w</clientId>                    \n",
      "                              <startDate>2024-09-18</startDate>\n",
      "                              <endDate>2024-09-18</endDate>\n",
      "                              <lineExternalNamePattern>WEB_HB_662</lineExternalNamePattern>            \n",
      "                              <hasRealtime>ALL</hasRealtime>\n",
      "                         </filter>\n",
      "                         \n",
      "               <options>\n",
      "                    <includeMatrixData>true</includeMatrixData>\n",
      "               </options>\n",
      "               \n",
      "                    </v15:createArchiveJob>\n",
      "                    \n",
      "               </soapenv:Body>\n",
      "          </soapenv:Envelope>\n",
      "                    \n",
      "no tar.gz\n",
      "<soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"><soap:Body><ns2:createArchiveJobResponse xmlns:ns2=\"http://v15.export.service.data.archive.itcs.hafas.hacon.de/\"><return><clientId>mvHU2OdQDJTwQD4w</clientId><exportId>784184b4-83db-4aa5-ba53-798531764b82</exportId><status>NEW</status><type>ARCHIVE_EXPORT</type></return></ns2:createArchiveJobResponse></soap:Body></soap:Envelope>\n",
      "exportId {} 784184b4-83db-4aa5-ba53-798531764b82\n",
      "2024-09-19 17:33:57.918903 Status: NEW\n",
      "2024-09-19 17:34:08.092073 Status: COMPLETED\n",
      "api_xml/demo/rt_archiv_15_2024-09-18_2024-09-18_alle_demo_matrix_True.xml gespeichert\n",
      "no tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703346/2963147006.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_rt_vbn_verlauf['canc'] = df_rt_vbn_verlauf['canc'].replace({'true':True,'false':False},regex=True)\n",
      "/tmp/ipykernel_703346/2963147006.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_rt_vbn_verlauf['has_rt'] = df_rt_vbn_verlauf['has_rt'].replace({'true':True,'false':False},regex=True)\n",
      "/tmp/ipykernel_703346/2963147006.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_rt_vbn_verlauf['additional'] = df_rt_vbn_verlauf['additional'].replace({'true':True,'false':False},regex=True)\n",
      "/tmp/ipykernel_703346/1951250727.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_rt_vbn_fahrten['journey_cancelled'] = df_rt_vbn_fahrten['journey_cancelled'].replace({'True':True,'False':False},regex=True)\n"
     ]
    }
   ],
   "source": [
    "gestern = (dt.date.today() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "\n",
    "start = gestern\n",
    "ende = gestern\n",
    "server = 'demo' #prod oder demo\n",
    "#lineExternalNamePattern = 'de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:,de:VBN-VGC:910:' #Gesamt VBN\n",
    "lineExternalNamePattern = 'WEB_HB_662' #Auswahl\n",
    "\n",
    "#Festlegen Prod oder Demosystem\n",
    "if server == 'prod':\n",
    "    clientID = 'PMQmY5p9y8kmoTno' #prod\n",
    "    api_version = 14\n",
    "    matrix = False #ab Version 15 true möglich\n",
    "    myUrl = f\"https://fahrplaner.vbn.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "else:\n",
    "    clientID = 'mvHU2OdQDJTwQD4w' #demo\n",
    "    api_version = 15\n",
    "    matrix = True #ab Version 15\n",
    "    myUrl = f\"https://vbn.demo.hafas.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "\n",
    "xml_request_dlid = def_xml_request_dlid(start=gestern, ende=gestern, api_version=api_version, clientID=clientID, matrix=matrix, lineExternalNamePattern=lineExternalNamePattern)\n",
    "print(xml_request_dlid)\n",
    "\n",
    "xml_path_pre = 'api_xml'\n",
    "\n",
    "xml_file = f\"rt_archiv_{api_version}_{start}_{ende}_alle_{server}_matrix_{matrix}.xml\"\n",
    "xml_path = os.path.join(xml_path_pre, server)\n",
    "xml_out = os.path.join(xml_path_pre, server, xml_file)\n",
    "tar_gz = f\"{xml_out}.tar.gz\"\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(xml_path, tar_gz)):\n",
    "    with tarfile.open(os.path.join(xml_path, tar_gz), 'r:gz') as tar:\n",
    "        # Extract all files to the specified directory    \n",
    "        tar.extractall(xml_path) \n",
    "else:\n",
    "    print('no tar.gz')   \n",
    "\n",
    "request_xml(api_version=api_version, xml_request=xml_request_dlid, xml_out=xml_out, myUrl=myUrl)\n",
    "df_rt_vbn_fahrten = import_rt_xml_to_df_fahrten(xml_out)\n",
    "df_rt_vbn_verlauf = import_rt_xml_to_df_verlauf(xml_out)\n",
    "\n",
    "df_rt_vbn_verlauf = type_df_verlauf(df_rt_vbn_verlauf)\n",
    "df_rt_vbn_fahrten = type_df_fahrten(df_rt_vbn_fahrten)\n",
    "\n",
    "xml_to_targz(xml_file=xml_file, xml_path=xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datum</th>\n",
       "      <th>fnr</th>\n",
       "      <th>destination</th>\n",
       "      <th>hasRealtime</th>\n",
       "      <th>realtimeHasEverBeenReported</th>\n",
       "      <th>vu</th>\n",
       "      <th>lineid</th>\n",
       "      <th>lineid_short</th>\n",
       "      <th>lineshort</th>\n",
       "      <th>reported_cancelled</th>\n",
       "      <th>journey_cancelled</th>\n",
       "      <th>ts_reported_cancelled</th>\n",
       "      <th>cancelled_kum</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>clientid</th>\n",
       "      <th>journeyrttype</th>\n",
       "      <th>fahrtstarttime</th>\n",
       "      <th>fahrtstartstationname</th>\n",
       "      <th>fahrtstartstationdhid</th>\n",
       "      <th>fahrtendtime</th>\n",
       "      <th>fahrtendstationname</th>\n",
       "      <th>fahrtendstationdhid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>1662012</td>\n",
       "      <td>Platjenwerbe</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Weser-Ems-Bus Betrieb Bremen</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0918-1662012-8012026800000#!ADD!#DBRB#</td>\n",
       "      <td>DBRB</td>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>2024-09-18T15:10:00+02:00</td>\n",
       "      <td>Osterholz-Scharmbeck-Buschhausen Grundschule</td>\n",
       "      <td>de:03356:72097::1</td>\n",
       "      <td>2024-09-18T16:12:00+02:00</td>\n",
       "      <td>Platjenwerbe Schule</td>\n",
       "      <td>de:03356:74053::1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>1662006</td>\n",
       "      <td>Platjenwerbe</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Weser-Ems-Bus Betrieb Bremen</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0918-1662006-8012026700000#!ADD!#DBRB#</td>\n",
       "      <td>DBRB</td>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>2024-09-18T13:23:00+02:00</td>\n",
       "      <td>Osterholz-Scharmbeck Neue Berufsschule</td>\n",
       "      <td>de:03356:72084::2</td>\n",
       "      <td>2024-09-18T14:05:00+02:00</td>\n",
       "      <td>Platjenwerbe Schule</td>\n",
       "      <td>de:03356:74053::1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>1662004</td>\n",
       "      <td>Platjenwerbe</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Weser-Ems-Bus Betrieb Bremen</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0918-1662004-8012026600000#!ADD!#DBRB#</td>\n",
       "      <td>DBRB</td>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>2024-09-18T12:28:00+02:00</td>\n",
       "      <td>Osterholz-Scharmbeck Neue Berufsschule</td>\n",
       "      <td>de:03356:72084::2</td>\n",
       "      <td>2024-09-18T13:05:00+02:00</td>\n",
       "      <td>Platjenwerbe Schule</td>\n",
       "      <td>de:03356:74053::1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>1662002</td>\n",
       "      <td>Platjenwerbe</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Weser-Ems-Bus Betrieb Bremen</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0918-1662002-8012026500000#!ADD!#DBRB#</td>\n",
       "      <td>DBRB</td>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>2024-09-18T11:33:00+02:00</td>\n",
       "      <td>Osterholz-Scharmbeck Neue Berufsschule</td>\n",
       "      <td>de:03356:72084::2</td>\n",
       "      <td>2024-09-18T12:10:00+02:00</td>\n",
       "      <td>Platjenwerbe Schule</td>\n",
       "      <td>de:03356:74053::1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-09-18</td>\n",
       "      <td>1662001</td>\n",
       "      <td>Buschhausen</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Weser-Ems-Bus Betrieb Bremen</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>WEB_HB_662</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0918-1662001-8012026400000#!ADD!#DBRB#</td>\n",
       "      <td>DBRB</td>\n",
       "      <td>SCHEDULED</td>\n",
       "      <td>2024-09-18T07:00:00+02:00</td>\n",
       "      <td>Platjenwerbe Schule</td>\n",
       "      <td>de:03356:74053::1</td>\n",
       "      <td>2024-09-18T07:48:00+02:00</td>\n",
       "      <td>Osterholz-Scharmbeck-Buschhausen Grundschule</td>\n",
       "      <td>de:03356:72097::1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       datum      fnr   destination  hasRealtime  realtimeHasEverBeenReported  \\\n",
       "0 2024-09-18  1662012  Platjenwerbe         True                         True   \n",
       "1 2024-09-18  1662006  Platjenwerbe         True                         True   \n",
       "2 2024-09-18  1662004  Platjenwerbe         True                         True   \n",
       "3 2024-09-18  1662002  Platjenwerbe         True                         True   \n",
       "4 2024-09-18  1662001   Buschhausen         True                         True   \n",
       "\n",
       "                             vu      lineid lineid_short lineshort  \\\n",
       "0  Weser-Ems-Bus Betrieb Bremen  WEB_HB_662   WEB_HB_662       662   \n",
       "1  Weser-Ems-Bus Betrieb Bremen  WEB_HB_662   WEB_HB_662       662   \n",
       "2  Weser-Ems-Bus Betrieb Bremen  WEB_HB_662   WEB_HB_662       662   \n",
       "3  Weser-Ems-Bus Betrieb Bremen  WEB_HB_662   WEB_HB_662       662   \n",
       "4  Weser-Ems-Bus Betrieb Bremen  WEB_HB_662   WEB_HB_662       662   \n",
       "\n",
       "   reported_cancelled  journey_cancelled ts_reported_cancelled  cancelled_kum  \\\n",
       "0               False              False                                False   \n",
       "1               False              False                                False   \n",
       "2               False              False                                False   \n",
       "3               False              False                                False   \n",
       "4               False              False                                False   \n",
       "\n",
       "                                 deviceid clientid journeyrttype  \\\n",
       "0  0918-1662012-8012026800000#!ADD!#DBRB#     DBRB     SCHEDULED   \n",
       "1  0918-1662006-8012026700000#!ADD!#DBRB#     DBRB     SCHEDULED   \n",
       "2  0918-1662004-8012026600000#!ADD!#DBRB#     DBRB     SCHEDULED   \n",
       "3  0918-1662002-8012026500000#!ADD!#DBRB#     DBRB     SCHEDULED   \n",
       "4  0918-1662001-8012026400000#!ADD!#DBRB#     DBRB     SCHEDULED   \n",
       "\n",
       "              fahrtstarttime                         fahrtstartstationname  \\\n",
       "0  2024-09-18T15:10:00+02:00  Osterholz-Scharmbeck-Buschhausen Grundschule   \n",
       "1  2024-09-18T13:23:00+02:00        Osterholz-Scharmbeck Neue Berufsschule   \n",
       "2  2024-09-18T12:28:00+02:00        Osterholz-Scharmbeck Neue Berufsschule   \n",
       "3  2024-09-18T11:33:00+02:00        Osterholz-Scharmbeck Neue Berufsschule   \n",
       "4  2024-09-18T07:00:00+02:00                           Platjenwerbe Schule   \n",
       "\n",
       "  fahrtstartstationdhid               fahrtendtime  \\\n",
       "0     de:03356:72097::1  2024-09-18T16:12:00+02:00   \n",
       "1     de:03356:72084::2  2024-09-18T14:05:00+02:00   \n",
       "2     de:03356:72084::2  2024-09-18T13:05:00+02:00   \n",
       "3     de:03356:72084::2  2024-09-18T12:10:00+02:00   \n",
       "4     de:03356:74053::1  2024-09-18T07:48:00+02:00   \n",
       "\n",
       "                            fahrtendstationname fahrtendstationdhid  \n",
       "0                           Platjenwerbe Schule   de:03356:74053::1  \n",
       "1                           Platjenwerbe Schule   de:03356:74053::1  \n",
       "2                           Platjenwerbe Schule   de:03356:74053::1  \n",
       "3                           Platjenwerbe Schule   de:03356:74053::1  \n",
       "4  Osterholz-Scharmbeck-Buschhausen Grundschule   de:03356:72097::1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rt_vbn_fahrten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Für Zusatzfahrten prod\n",
    "\n",
    "- Abfragen aller Daten über die RTTypes\n",
    "    - REALTIME_EXTRA und weitere\n",
    "    - DEVIATION_OF_SCHEDULED\n",
    "    - etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xml_request_zusatz_umleitung = f\"\"\"\n",
    "                                <soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\" \n",
    "               xmlns:v{api_version}=\"http://v{api_version}.export.service.data.archive.itcs.hafas.hacon.de/\">\n",
    "               <soapenv:Header/><soapenv:Body><v{api_version}:createArchiveJob>\n",
    "               <filter>\n",
    "                    <clientId>{clientID}</clientId>         \n",
    "                    <startDate>{gestern}</startDate>\n",
    "                    <endDate>{gestern}</endDate>\n",
    "                    <filterJourneyRtTypeList>REALTIME_EXTRA</filterJourneyRtTypeList>\n",
    "                    <filterJourneyRtTypeList>REALTIME_EXTRA_REPLACEMENT</filterJourneyRtTypeList>\n",
    "                    <filterJourneyRtTypeList>REALTIME_EXTRA_REPORTED</filterJourneyRtTypeList>\n",
    "                    <filterJourneyRtTypeList>REALTIME_EXTRA_MAINTENANCE</filterJourneyRtTypeList>\n",
    "                    <filterJourneyRtTypeList>DEVIATION_OF_SCHEDULED</filterJourneyRtTypeList>\n",
    "                    <filterJourneyRtTypeList>DEVIATION_OF_REALTIME_EXTRA</filterJourneyRtTypeList>         \n",
    "                    <filterJourneyRtTypeList>DEVIATION_OF_REPLACEMENT</filterJourneyRtTypeList>             \n",
    "                    <filterJourneyRtTypeList>SUPPLEMENTARY</filterJourneyRtTypeList>'                \n",
    "                    <filterJourneyRtTypeList>UNKNOWN</filterJourneyRtTypeList>               \n",
    "                    <hasRealtime>ALL</hasRealtime>\n",
    "               </filter>\n",
    "               </v{api_version}:createArchiveJob></soapenv:Body></soapenv:Envelope>\n",
    "               \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pretty_xml(xml_request_zusatz_umleitung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestern = (dt.date.today() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "\n",
    "start = gestern\n",
    "ende = gestern\n",
    "server = 'prod' #prod oder demo\n",
    "#lineExternalNamePattern = 'de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:,de:VBN-VGC:910:' #Gesamt VBN\n",
    "lineExternalNamePattern = '\tde:VBN:659:*' #Auswahl\n",
    "\n",
    "#Festlegen Prod oder Demosystem\n",
    "if server == 'prod':\n",
    "    clientID = 'PMQmY5p9y8kmoTno' #prod\n",
    "    api_version = 14\n",
    "    matrix = False #ab Version 15\n",
    "    myUrl = f\"https://fahrplaner.vbn.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "else:\n",
    "    clientID = 'mvHU2OdQDJTwQD4w' #demo\n",
    "    api_version = 15\n",
    "    matrix = True #ab Version 15\n",
    "    myUrl = f\"https://vbn.demo.hafas.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "\n",
    "xml_path_pre = 'api_xml'\n",
    "server = 'prod'\n",
    "xml_file = f\"rt_archiv_{gestern}_zusatz.xml\"\n",
    "\n",
    "xml_path = os.path.join(xml_path_pre, server)\n",
    "xml_out = os.path.join(xml_path_pre, server, xml_file)\n",
    "\n",
    "request_xml(api_version=api_version, xml_request=xml_request_zusatz_umleitung, xml_out=xml_out, myUrl=myUrl)\n",
    "df_rt_zusatz = import_rt_xml_to_df_fahrten(xml_file=xml_out)\n",
    "\n",
    "#xml_to_targz(xml_file=xml_file, xml_path=xml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben der Daten nach Parquet (prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rt_vbn_fahrten.to_parquet(f\"out/parquet/{server}/fahrten_{gestern.replace('-', '_')}.parquet\")\n",
    "df_rt_zusatz.to_parquet(f\"out/parquet/{server}/zusatz_{gestern.replace('-', '_')}.parquet\")\n",
    "df_rt_vbn_verlauf.to_parquet(f\"out/parquet/{server}/verlauf_{gestern.replace('-', '_')}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo (ohne Zusatzfahrten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestern = (dt.date.today() - timedelta(1)).strftime('%Y-%m-%d')\n",
    "\n",
    "start = gestern\n",
    "ende = gestern\n",
    "server = 'prod' #prod oder demo\n",
    "#lineExternalNamePattern = 'de:VBN:*,de:hvv:RB33:,de:hvv:RB41:,de:hvv:RE4:,de:VBN-VGC:910:' #Gesamt VBN\n",
    "lineExternalNamePattern = 'de:VBN:659:*' #Auswahl\n",
    "\n",
    "#Festlegen Prod oder Demosystem\n",
    "if server == 'prod':\n",
    "    clientID = 'PMQmY5p9y8kmoTno' #prod\n",
    "    api_version = 14\n",
    "    matrix = False #ab Version 15\n",
    "    myUrl = f\"https://fahrplaner.vbn.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "else: #demo\n",
    "    clientID = 'mvHU2OdQDJTwQD4w' #demo\n",
    "    api_version = 15\n",
    "    matrix = True #ab Version 15 möglich\n",
    "    myUrl = f\"https://vbn.demo.hafas.de/archive/services/archiveExportService/v{api_version}?wsdl\"\n",
    "\n",
    "xml_request_dlid = def_xml_request_dlid(start=gestern, ende=gestern, api_version=api_version, clientID=clientID, matrix=matrix, lineExternalNamePattern=lineExternalNamePattern)\n",
    "print(xml_request_dlid)\n",
    "\n",
    "xml_path_pre = 'api_xml'\n",
    "\n",
    "xml_file = f\"rt_archiv_{api_version}_{start}_{ende}_alle_{server}_matrix_{matrix}.xml\"\n",
    "xml_path = os.path.join(xml_path_pre, server)\n",
    "xml_out = os.path.join(xml_path_pre, server, xml_file)\n",
    "tar_gz = f\"{xml_out}.tar.gz\"\n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(xml_path, tar_gz)):\n",
    "    with tarfile.open(os.path.join(xml_path, tar_gz), 'r:gz') as tar:\n",
    "        # Extract all files to the specified directory    \n",
    "        tar.extractall(xml_path) \n",
    "else:\n",
    "    print('no tar.gz')   \n",
    "\n",
    "request_xml(api_version=api_version, xml_request=xml_request_dlid, xml_out=xml_out, myUrl=myUrl)\n",
    "df_rt_vbn_fahrten = import_rt_xml_to_df_fahrten(xml_out)\n",
    "df_rt_vbn_verlauf = import_rt_xml_to_df_verlauf(xml_out)\n",
    "\n",
    "df_rt_vbn_verlauf = type_df_verlauf(df_rt_vbn_verlauf)\n",
    "df_rt_vbn_fahrten = type_df_fahrten(df_rt_vbn_fahrten)\n",
    "\n",
    "#xml_to_targz(xml_file=xml_file, xml_path=xml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rt_vbn_fahrten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"matrix: {matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben der Daten nach Parquet (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rt_vbn_fahrten.to_parquet(f\"out/parquet/{server}/fahrten_{gestern.replace('-', '_')}.parquet\")\n",
    "\n",
    "df_rt_vbn_verlauf.to_parquet(f\"out/parquet/{server}/verlauf_{gestern.replace('-', '_')}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
